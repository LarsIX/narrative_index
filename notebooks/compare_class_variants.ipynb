{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "008bb9da",
   "metadata": {},
   "source": [
    "Notebook to compare binary vs. three-class classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "833e5d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from IPython.display import display, Markdown\n",
    "import sys\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a29ea999",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_17244\\321895797.py:36: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_author = pd.concat([df_author, subset], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 1, 2, 3}\n"
     ]
    }
   ],
   "source": [
    "# Set root and target dir\n",
    "project_root = Path.cwd().parent\n",
    "data_dir = project_root / \"data\" \n",
    "articles_dir = data_dir / \"interim\" \n",
    "\n",
    "# Define columns to keep (in lowercase for consistency)\n",
    "target_columns = [\n",
    "    'article_id', 'title','hype_level'\n",
    "]\n",
    "\n",
    "# List of author-annotated CSV files\n",
    "filenames_author = [\n",
    "    \"articles_WSJ_batch_one_author.csv\",\n",
    "    \"articles_WSJ_batch_two_author.csv\",\n",
    "    \"articles_WSJ_batch_three_author.csv\",\n",
    "    \"articles_WSJ_batch_four_subsample_author.csv\"\n",
    "]\n",
    "\n",
    "# Initialize empty DataFrame for author annotations\n",
    "df_author = pd.DataFrame(columns=target_columns)\n",
    "\n",
    "# Loop through each author file\n",
    "for csv in filenames_author:\n",
    "    path = articles_dir / csv\n",
    "\n",
    "    # Read CSV normally\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    # Convert all column names to lowercase\n",
    "    df.columns = df.columns.str.lower()\n",
    "\n",
    "    # Keep only relevant columns\n",
    "    subset = df[target_columns].copy()\n",
    "\n",
    "    # Append to cumulative author DataFrame\n",
    "    df_author = pd.concat([df_author, subset], ignore_index=True)\n",
    "\n",
    "# List of annotator-labeled CSV files\n",
    "filenames_annotator = [\n",
    "    \"articles_WSJ_batch_one_annotator.csv\",\n",
    "    \"articles_WSJ_batch_two_annotator.csv\",\n",
    "    \"articles_WSJ_batch_three_annotator.csv\",\n",
    "    \"articles_WSJ_batch_four_annotator.csv\"\n",
    "]\n",
    "\n",
    "# Initialize empty DataFrame for annotator annotations\n",
    "df_annotator = pd.DataFrame(columns=target_columns)\n",
    "\n",
    "# Loop through each annotator file and handle encoding issues\n",
    "for csv in filenames_annotator:\n",
    "    path = articles_dir / csv\n",
    "\n",
    "    try:\n",
    "        # Attempt UTF-8 encoding\n",
    "        df = pd.read_csv(path, encoding='utf-8')\n",
    "    except UnicodeDecodeError:\n",
    "        # Fallback to cp1252 encoding (common Windows encoding)\n",
    "        df = pd.read_csv(path, encoding='cp1252')\n",
    "\n",
    "    # Convert all column names to lowercase\n",
    "    df.columns = df.columns.str.lower()\n",
    "\n",
    "    # Keep only relevant columns\n",
    "    subset = df[target_columns].copy()\n",
    "\n",
    "    # Append to cumulative annotator DataFrame\n",
    "    df_annotator = pd.concat([df_annotator, subset], ignore_index=True)\n",
    "print(set(df_annotator.hype_level))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df8cc8d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Unique values in hype_level_ann:\n",
      "{0, 1, 2, 3}\n",
      "\n",
      "Unique values in hype_level_auth:\n",
      "{0.0, 1.0, 2.0}\n"
     ]
    }
   ],
   "source": [
    "df_merged = df_author.merge(df_annotator, on=\"article_id\", suffixes=(\"_auth\", \"_ann\"))\n",
    "\n",
    "# verify that 493 are in the overlapping df\n",
    "print(318 + 1/4 * 700 == len(df_merged))\n",
    "\n",
    "# verify values in hype  columns\n",
    "print(\"Unique values in hype_level_ann:\")\n",
    "print(set(df_merged['hype_level_ann'].dropna()))\n",
    "\n",
    "print(\"\\nUnique values in hype_level_auth:\")\n",
    "print(set(df_merged['hype_level_auth'].dropna()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "626457d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_17244\\2005606161.py:2: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_merged[\"hype_level_ann\"] = df_merged[\"hype_level_ann\"].fillna(0).replace(3,2).astype(int)\n"
     ]
    }
   ],
   "source": [
    "# ensure consistency\n",
    "df_merged[\"hype_level_ann\"] = df_merged[\"hype_level_ann\"].fillna(0).replace(3,2).astype(int)\n",
    "df_merged[\"hype_level_auth\"] = df_merged[\"hype_level_auth\"].fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ad0233",
   "metadata": {},
   "source": [
    "Compare three-class annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fca046c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 111 aritcles with different hype-levels, which approximiates 23.0%\n"
     ]
    }
   ],
   "source": [
    "# find total divergence\n",
    "n_dif_three = np.sum(df_merged.hype_level_auth != df_merged.hype_level_ann)\n",
    "n_dif_three_rel = n_dif_three / len(df_merged)\n",
    "\n",
    "# show results\n",
    "print(f'There are {n_dif_three} aritcles with different hype-levels, which approximiates {round(n_dif_three_rel,2)*100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5652509c",
   "metadata": {},
   "source": [
    "Compare binary annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7e2da3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 69 articles with different hype levels, which is approximately 14.0%.\n"
     ]
    }
   ],
   "source": [
    "# Transform hype scores into binary format\n",
    "df_merged[\"hype_level_ann\"] = df_merged[\"hype_level_ann\"].fillna(0).replace([3, 2], 1).astype(int)\n",
    "df_merged[\"hype_level_auth\"] = df_merged[\"hype_level_auth\"].fillna(0).replace(2, 1).astype(int)\n",
    "\n",
    "# Count divergences between annotator and author\n",
    "n_dif_three_bin = np.sum(df_merged.hype_level_auth != df_merged.hype_level_ann)\n",
    "n_dif_three_rel_bin = n_dif_three_bin / len(df_merged)\n",
    "\n",
    "# Display result as percentage\n",
    "print(f'There are {n_dif_three_bin} articles with different hype levels, which is approximately {round(n_dif_three_rel_bin * 100, 2)}%.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3dc9b51",
   "metadata": {},
   "source": [
    "Compare binary annatoation with results of dictionary-based Finbert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "76b8fb45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   article_id  image_src         scanned_time  \\\n",
      "0       13068        NaN  2025-04-01 09:47:17   \n",
      "1       13069        NaN  2025-04-01 09:47:27   \n",
      "2       13070        NaN  2025-04-01 09:47:37   \n",
      "3       13071        NaN  2025-04-01 09:47:49   \n",
      "4       13072        NaN  2025-04-01 09:47:59   \n",
      "\n",
      "                                               title  \\\n",
      "0  Baidu Terminates $3.6B Deal to Buy JOYY’s Chin...   \n",
      "1                The Military’s Phantom ‘Extremists’   \n",
      "2                  Double Dipping in Opioid Lawsuits   \n",
      "3                     Xi Jinping Says Happy New Year   \n",
      "4  Israel Reshuffles Forces, Prepares for Long-Te...   \n",
      "\n",
      "                                           sub_title  \\\n",
      "0  As of the end of December, the closing conditi...   \n",
      "1  An independent study puts to rest another fals...   \n",
      "2  OptumRx seeks to disqualify Motley Rice for a ...   \n",
      "3  China’s leader tries to influence Taiwan’s Jan...   \n",
      "4  Resisting pressure from U.S. to wind down the ...   \n",
      "\n",
      "                                              corpus  index_id  id  \\\n",
      "0  Title: Baidu Terminates $3.6B Deal to Buy JOYY...         1   1   \n",
      "1  Title: The Military’s Phantom ‘Extremists’\\n\\n...         2   2   \n",
      "2  Title: Double Dipping in Opioid Lawsuits\\n\\nAd...         3   3   \n",
      "3  Title: Xi Jinping Says Happy New Year\\n\\nAdver...         4   4   \n",
      "4  Title: Israel Reshuffles Forces, Prepares for ...         5   5   \n",
      "\n",
      "                  date                                               link  \\\n",
      "0  2024-01-01 00:00:00  https://www.wsj.com/business/telecom/baidu-ter...   \n",
      "1  2024-01-01 00:00:00  https://www.wsj.com/opinion/military-extremist...   \n",
      "2  2024-01-01 00:00:00  https://www.wsj.com/opinion/double-dipping-in-...   \n",
      "3  2024-01-01 00:00:00  https://www.wsj.com/opinion/xi-jinping-says-ha...   \n",
      "4  2024-01-01 00:00:00  https://www.wsj.com/world/middle-east/israel-r...   \n",
      "\n",
      "    section                                     cleaned_corpus ai_window  \\\n",
      "0  business  Jan. 1, 644 pm. ET 2 min. As of the end of. De...       NaN   \n",
      "1   opinion  REVIEW. OUTLOOK. Jan. 1, 545 pm. ET 834 3 min....       NaN   \n",
      "2   opinion  REVIEW. OUTLOOK. OptumRx seeks to disqualify. ...       NaN   \n",
      "3   opinion  REVIEW. OUTLOOK. China's leader tries to influ...       NaN   \n",
      "4     world  Israel. Reshuffles. Forces,. Prepares for. Lon...       NaN   \n",
      "\n",
      "   predicted_label predicted_class  \n",
      "0                0    No narrative  \n",
      "1                0    No narrative  \n",
      "2                0    No narrative  \n",
      "3                0    No narrative  \n",
      "4                0    No narrative  \n"
     ]
    }
   ],
   "source": [
    "# load binary predictions for 2024 \n",
    "fin_bin_pred = pd.read_csv(data_dir / \"processed\" / \"variables\" / \"FinBERT_binary_prediction_2024.csv\")\n",
    "\n",
    "#verify load\n",
    "print(fin_bin_pred.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "de69b60b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "article_id",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "image_src",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "scanned_time",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "sub_title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "corpus",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "index_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "date",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "link",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "section",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "cleaned_corpus",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "ai_window",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "predicted_label",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "predicted_class",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "76c70b22-f058-49db-85e2-b12a7840d2a6",
       "rows": [],
       "shape": {
        "columns": 15,
        "rows": 0
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>image_src</th>\n",
       "      <th>scanned_time</th>\n",
       "      <th>title</th>\n",
       "      <th>sub_title</th>\n",
       "      <th>corpus</th>\n",
       "      <th>index_id</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>link</th>\n",
       "      <th>section</th>\n",
       "      <th>cleaned_corpus</th>\n",
       "      <th>ai_window</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>predicted_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [article_id, image_src, scanned_time, title, sub_title, corpus, index_id, id, date, link, section, cleaned_corpus, ai_window, predicted_label, predicted_class]\n",
       "Index: []"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# subset for overlaps with annotated df\n",
    "df_merged[\"article_id\"] = df_merged[\"article_id\"].astype(int)\n",
    "fin_bin_pred[\"article_id\"] = fin_bin_pred[\"article_id\"].astype(int)\n",
    "fin_sub = fin_bin_pred[fin_bin_pred[\"article_id\"].isin(df_merged[\"article_id\"])]\n",
    "\n",
    "fin_sub"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
