{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e32b65f",
   "metadata": {},
   "source": [
    "Notebook to train a custom FinBERT model on the binary AINI dataset to annotate WSJ articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094a2b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import random\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "from datasets import DatasetDict, Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer, set_seed\n",
    "from transformers import DataCollatorWithPadding, EarlyStoppingCallback,AutoConfig, get_scheduler,BertModel\n",
    "from IPython.display import display, Markdown \n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import torch.nn as nn\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from torch.optim import AdamW\n",
    "from sklearn.model_selection import train_test_split\n",
    "import spacy\n",
    "import nltk\n",
    "\n",
    "try:\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "except:\n",
    "    nltk.download(\"punkt\")\n",
    "    import en_core_web_sm\n",
    "    nlp = en_core_web_sm.load()\n",
    "\n",
    "# append model path\n",
    "notebook_dir = Path.cwd()\n",
    "project_root = notebook_dir.parent  \n",
    "sys.path.insert(0, str(project_root))  \n",
    "\n",
    "from src.modelling.CustomFinBERT import CustomFinBERT\n",
    "from src.modelling.ai_windows import extract_multiple_ai_snippets_with_context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268ab0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set project root, assumes being in /notebooks\n",
    "project_root = Path.cwd().parent\n",
    "\n",
    "# Path to annotated cvs\n",
    "articles_dir = project_root / \"data\" / \"processed\" / \"articles\" / \"annotated_subsample_WSJ_final.csv\"\n",
    "\n",
    "# read and merge annotated cvs\n",
    "df = pd.read_csv(articles_dir)\n",
    "\n",
    "# verify merge\n",
    "print(f\" {len(df)} total rows.\")\n",
    "display(df.head(5))\n",
    "print(set(df.hype_level.values))\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a453daa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure integrity\n",
    "print(df.corpus.isna().sum())\n",
    "labeled_df = df.copy()\n",
    "labeled_df.loc[labeled_df[\"corpus\"].isna(), \"corpus\"] = df.loc[df[\"corpus\"].isna(), \"cleaned_corpus\"]\n",
    "\n",
    "# verify fix\n",
    "print(labeled_df.corpus.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138719c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename column\n",
    "labeled_df.rename(columns={\"hype_level\": \"label\"}, inplace=True)\n",
    "\n",
    "# binary label creation\n",
    "labeled_df[\"label\"] = labeled_df[\"label\"].apply(lambda x: 1 if x in [1.0, 2.0, 3.0] else 0)\n",
    "\n",
    "# merging cleaned corpus and title on corpus\n",
    "labeled_df[\"corpus\"] = \"Title: \" + labeled_df[\"title\"] + \"\\n\\n\" + labeled_df[\"corpus\"]\n",
    "\n",
    "#  Create class weights\n",
    "labels = labeled_df[\"label\"]\n",
    "class_weights = compute_class_weight(\"balanced\", classes=np.unique(labels), y=labels)\n",
    "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float)\n",
    "\n",
    "\n",
    "# Convert to HF Dataset\n",
    "hf_labeled_df = Dataset.from_pandas(labeled_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7cea6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_truncate(batch, tokenizer):\n",
    "    encoded = tokenizer(batch[\"corpus\"], add_special_tokens=False)\n",
    "    input_ids = encoded[\"input_ids\"] # word tokens mapped to ids\n",
    "    attention_mask = encoded[\"attention_mask\"] # 0 if padded\n",
    "\n",
    "    truncated_input_ids = []\n",
    "    truncated_attention_mask = []\n",
    "\n",
    "    for ids, mask in zip(input_ids, attention_mask):\n",
    "        \n",
    "        # limit input length\n",
    "        if len(ids) > 510:\n",
    "            new_ids = ids[:128] + ids[-382:]\n",
    "            new_mask = mask[:128] + mask[-382:]\n",
    "        else:\n",
    "            new_ids = ids\n",
    "            new_mask = mask\n",
    "\n",
    "        # Add [CLS] and [SEP]\n",
    "        new_ids = [tokenizer.cls_token_id] + new_ids + [tokenizer.sep_token_id]\n",
    "        new_mask = [1] + new_mask + [1]\n",
    "\n",
    "        pad_len = 512 - len(new_ids)\n",
    "        new_ids += [tokenizer.pad_token_id] * pad_len\n",
    "        new_mask += [0] * pad_len\n",
    "\n",
    "        truncated_input_ids.append(new_ids)\n",
    "        truncated_attention_mask.append(new_mask)\n",
    "\n",
    "    return {\"input_ids\": truncated_input_ids, \"attention_mask\": truncated_attention_mask}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523ec538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seeds for reproducibility\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "set_seed(seed)\n",
    "\n",
    "# Convert to pandas and extract AI-focused snippets\n",
    "df_labeled = hf_labeled_df.to_pandas()\n",
    "df_labeled = extract_multiple_ai_snippets_with_context(df_labeled, text_col='corpus', output_col='ai_window',context_window=2)\n",
    "\n",
    "# Stratified split: 70% train, 30% temp\n",
    "train_df, temp_df = train_test_split(\n",
    "    df_labeled,\n",
    "    test_size=0.3,\n",
    "    stratify=labeled_df[\"label\"],\n",
    "    random_state=seed\n",
    ")\n",
    "\n",
    "# Stratified split: 2/3 test, 1/3 eval from temp (→ 20% / 10%)\n",
    "eval_df, test_df  = train_test_split(\n",
    "    temp_df,\n",
    "    test_size=1/3,\n",
    "    stratify=temp_df[\"label\"],\n",
    "    random_state=seed\n",
    ")\n",
    "\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ProsusAI/finbert\")\n",
    "\n",
    "# Tokenization function\n",
    "def tokenize(example):\n",
    "    return tokenizer(\n",
    "        example[\"ai_window\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=512\n",
    "    )\n",
    "\n",
    "# Convert to Hugging Face Datasets\n",
    "train_dataset = Dataset.from_pandas(train_df.reset_index(drop=True))\n",
    "test_dataset = Dataset.from_pandas(test_df.reset_index(drop=True))\n",
    "eval_dataset = Dataset.from_pandas(eval_df.reset_index(drop=True))\n",
    "\n",
    "# fixing label for tensors\n",
    "def fix_labels(example):\n",
    "    return {\"labels\": int(example[\"label\"])}\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize)\n",
    "train_dataset = train_dataset.map(fix_labels)\n",
    "\n",
    "eval_dataset = eval_dataset.map(tokenize)\n",
    "eval_dataset = eval_dataset.map(fix_labels)\n",
    "\n",
    "test_dataset = test_dataset.map(tokenize)\n",
    "test_dataset = test_dataset.map(fix_labels)\n",
    "\n",
    "\n",
    "\n",
    "# prepare dictionary for trainer\n",
    "dataset_dict = DatasetDict({\n",
    "    \"train\": train_dataset,\n",
    "    \"test\": test_dataset,\n",
    "    \"eval\": eval_dataset\n",
    "})\n",
    "\n",
    "# create class weights\n",
    "labels = labeled_df[\"label\"]\n",
    "class_weights = compute_class_weight(class_weight=\"balanced\", classes=np.unique(labels), y=labels)\n",
    "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc474ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model path and label mappings\n",
    "model_path = \"ProsusAI/finbert\"\n",
    "id2label = {0: \"No narrative\", 1: \"narrative\"}\n",
    "label2id = {v: k for k, v in id2label.items()}\n",
    "\n",
    "# Load and customize config\n",
    "config = AutoConfig.from_pretrained(\n",
    "    model_path,\n",
    "    num_labels=2,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    "    hidden_dropout_prob=0.1,\n",
    "    attention_probs_dropout_prob=0.1\n",
    ")\n",
    "\n",
    "# Load pretrained backbone\n",
    "backbone = BertModel.from_pretrained(model_path)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "class_weights_tensor = class_weights_tensor.to(device)\n",
    "\n",
    "# Instantiate the model\n",
    "model = CustomFinBERT(backbone, class_weights_tensor, config).to(device)\n",
    "\n",
    "print(f\"Model is on device: {next(model.parameters()).device}\")\n",
    "\n",
    "# Format datasets\n",
    "columns = [\"input_ids\", \"attention_mask\", \"labels\"]\n",
    "train_dataset.set_format(type=\"torch\", columns=columns)\n",
    "test_dataset.set_format(type=\"torch\", columns=columns)\n",
    "eval_dataset.set_format(type=\"torch\", columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581fd134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# narrativerparameters \n",
    "lr = 2e-5\n",
    "batch_size = 4\n",
    "num_epochs = 15\n",
    "\n",
    "# data collator for padding\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir= project_root / \"models\" / \"FINBERT_Binary\",\n",
    "    learning_rate=lr,\n",
    "    logging_dir= project_root / \"models\" / \"FINBERT_Binary\",\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=num_epochs,\n",
    "    logging_strategy=\"epoch\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,\n",
    "    load_best_model_at_end=True,\n",
    "    save_total_limit=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9757c3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze all parameters in the FinBERT encoder\n",
    "for name, param in model.backbone.named_parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Unfreeze the classification head and optional with ( name or \"encoder.layer.11\" in ) the last encoder layer (layer.11)\n",
    "for name, param in model.named_parameters():\n",
    "    if \"classifier\" or \"encoder.layer.11\" in name:\n",
    "        param.requires_grad = True\n",
    "\n",
    "\n",
    "# Print a summary of how many parameters are trainable\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Trainable parameters: {trainable_params:,} / {total_params:,} ({trainable_params / total_params:.2%})\")\n",
    "\n",
    "# Optionally, list all parameter names that are currently trainable\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f\"[✓] {name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b44d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(labels, preds),\n",
    "        \"f1_macro\": f1_score(labels, preds, average=\"macro\"),\n",
    "        \"precision_macro\": precision_score(labels, preds, average=\"macro\", zero_division=0),\n",
    "        \"recall_macro\": recall_score(labels, preds, average=\"macro\", zero_division=0),\n",
    "        \"f1_weighted\": f1_score(labels, preds, average=\"weighted\"),\n",
    "        \"precision_weighted\": precision_score(labels, preds, average=\"weighted\", zero_division=0),\n",
    "        \"recall_weighted\": recall_score(labels, preds, average=\"weighted\", zero_division=0),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1371a5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check on label values\n",
    "unique_labels = set(train_dataset[\"labels\"].tolist())\n",
    "print(\"Unique labels in training data:\", unique_labels)\n",
    "assert all(label in [0, 1] for label in unique_labels), \"Found unexpected label values!\"\n",
    "\n",
    "# Ensure GPU is used   \n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d477102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train them model\n",
    "    \n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset, # 70% training set\n",
    "    eval_dataset=eval_dataset, # 20% training set\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding=True),\n",
    "    compute_metrics=compute_metrics, # metrics as defined above\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=4)],\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbffc92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define save path\n",
    "project_root = Path.cwd().parent\n",
    "save_dir = project_root / \"models\" / \"FinBERT_Binary\" \n",
    "save_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save model, tokenizer and configd\n",
    "trainer.save_model(save_dir)\n",
    "tokenizer.save_pretrained(save_dir)\n",
    "config.save_pretrained(save_dir)  \n",
    "\n",
    "# Extract log history from training\n",
    "log_history = trainer.state.log_history\n",
    "\n",
    "# Convert to DataFrame\n",
    "log_df = pd.DataFrame(log_history)\n",
    "\n",
    "# Filter out entries without epoch information\n",
    "log_df = log_df[log_df['epoch'].notna()].copy()\n",
    "\n",
    "# Save full training logs\n",
    "log_df.to_csv(f\"{save_dir}/full_training_metrics.csv\", index=False)\n",
    "#print(log_df)\n",
    "\n",
    "# Save optimizer and scheduler state\n",
    "torch.save(trainer.optimizer.state_dict(), f\"{save_dir}/optimizer.pt\")\n",
    "torch.save(trainer.lr_scheduler.state_dict(), f\"{save_dir}/scheduler.pt\")\n",
    "torch.save(class_weights_tensor, save_dir / \"class_weights.pt\")\n",
    "\n",
    "# Save config details\n",
    "with open(f\"{save_dir}/config_summary.txt\", \"w\") as f:\n",
    "    f.write(f\"Model: {save_dir}\\n\")\n",
    "    f.write(f\"Learning Rate: {training_args.learning_rate}\\n\")\n",
    "    f.write(f\"Epochs: {training_args.num_train_epochs}\\n\")\n",
    "    f.write(f\"Batch Size: {training_args.per_device_train_batch_size}\\n\")\n",
    "    f.write(\"Tokenizer: ProsusAI/finbert\\n\")\n",
    "    f.write(\"Special preprocessing: large_ai_snippets_with_context=2\\n\")\n",
    "    f.write(\"Additional finetuning: encoder.layer.11 \\n\")\n",
    "    f.write(\"Label mapping: {0: 'No narrative', 1: 'narrative'}\\n\")\n",
    "\n",
    "# Run prediction on eval set (not test set)\n",
    "eval_output = trainer.predict(eval_dataset)\n",
    "\n",
    "# Extract predictions and true labels\n",
    "eval_preds = np.argmax(eval_output.predictions, axis=1)\n",
    "eval_labels = eval_output.label_ids\n",
    "\n",
    "# Create DataFrame with predictions\n",
    "eval_results_df = pd.DataFrame({\n",
    "    \"text\": eval_dataset[\"ai_window\"],\n",
    "    \"true_label\": eval_labels,\n",
    "    \"predicted_label\": eval_preds\n",
    "})\n",
    "\n",
    "# Map label IDs to names\n",
    "id2label =  {0: 'No narrative', 1: 'narrative'}\n",
    "eval_results_df[\"true_label_name\"] = eval_results_df[\"true_label\"].map(id2label)\n",
    "eval_results_df[\"predicted_label_name\"] = eval_results_df[\"predicted_label\"].map(id2label)\n",
    "\n",
    "# Save predictions\n",
    "eval_results_df.to_csv(f\"{save_dir}/eval_predictions.csv\", index=False)\n",
    "\n",
    "# Save evaluation classification report\n",
    "report = classification_report(eval_labels, eval_preds, target_names=list(id2label.values()))\n",
    "with open(f\"{save_dir}/eval_classification_report.txt\", \"w\") as f:\n",
    "    f.write(report)\n",
    "\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daab5af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run prediction\n",
    "output = trainer.predict(eval_dataset)\n",
    "\n",
    "# Extract predicted and true labels\n",
    "preds = np.argmax(output.predictions, axis=1)\n",
    "true = output.label_ids\n",
    "\n",
    "# Define label mappings\n",
    "id2label = {0: \"No narrative\", 1: \"narrative\"}\n",
    "\n",
    "# Create full DataFrame\n",
    "results_df = pd.DataFrame({\n",
    "    \"text\": eval_dataset[\"ai_window\"],\n",
    "    \"true_label\": true,\n",
    "    \"predicted_label\": preds,\n",
    "    \"true_label_name\": [id2label[i] for i in true],\n",
    "    \"predicted_label_name\": [id2label[i] for i in preds]\n",
    "})\n",
    "\n",
    "# Filter misclassified samples\n",
    "misclassified_df = results_df[results_df[\"true_label\"] != results_df[\"predicted_label\"]]\n",
    "\n",
    "# Save to CSV\n",
    "misclassified_df.to_csv(\"misclassified_eval_samples.csv\", index=False)\n",
    "\n",
    "# Adjust pandas display options for full text visibility\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "# Save model state dict manually\n",
    "torch.save(model.state_dict(), save_dir / \"pytorch_model.bin\")\n",
    "\n",
    "# Save config and tokenizer\n",
    "config.save_pretrained(save_dir)\n",
    "tokenizer.save_pretrained(save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5331871",
   "metadata": {},
   "source": [
    "Just for FINAL evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb044780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract log history\n",
    "log_history = trainer.state.log_history\n",
    "\n",
    "# Convert to DataFrame\n",
    "log_df = pd.DataFrame(log_history)\n",
    "\n",
    "# 3. Filter out irrelevant entries (like those without epoch info)\n",
    "log_df = log_df[log_df['epoch'].notna()].copy()\n",
    "\n",
    "# Save model and tokenizer\n",
    "trainer.save_model(save_dir)\n",
    "tokenizer.save_pretrained(save_dir)\n",
    "\n",
    "# Save full logs with all metrics\n",
    "log_df.to_csv(f\"{save_dir}/full_training_metrics.csv\", index=False)\n",
    "\n",
    "# Print or display metrics\n",
    "print(log_df)\n",
    "\n",
    "# Save optimizer and learning rate scheduler state\n",
    "torch.save(trainer.optimizer.state_dict(), f\"{save_dir}/optimizer.pt\")\n",
    "torch.save(trainer.lr_scheduler.state_dict(), f\"{save_dir}/scheduler.pt\")\n",
    "\n",
    "# write model details to txt\n",
    "with open(f\"{save_dir}/config_summary.txt\", \"w\") as f:\n",
    "    f.write(f\"Model: {save_dir}\\n\")\n",
    "    f.write(f\"Learning Rate: {training_args.learning_rate}\\n\")\n",
    "    f.write(f\"Epochs: {training_args.num_train_epochs}\\n\")\n",
    "    f.write(f\"Batch Size: {training_args.per_device_train_batch_size}\\n\")\n",
    "    f.write(\"Tokenizer: ProsusAI/finbert\\n\")\n",
    "    f.write(\"Special preprocessing: large_ai_snippets_with_context=2\\n\")\n",
    "    f.write(\"Additional finetuning:  \")\n",
    "    f.write(\"Label mapping: {0: 'No narrative', 1: 'narrative'}\\n\")\n",
    "\n",
    "# Run prediction on test set\n",
    "test_output = trainer.predict(test_dataset)\n",
    "\n",
    "# Extract predictions and true labels\n",
    "test_preds = np.argmax(test_output.predictions, axis=1)\n",
    "test_labels = test_output.label_ids\n",
    "\n",
    "# Save raw predictions and true labels to CSV\n",
    "test_results_df = pd.DataFrame({\n",
    "    \"text\": test_dataset[\"ai_window\"],\n",
    "    \"true_label\": test_labels,\n",
    "    \"predicted_label\": test_preds\n",
    "})\n",
    "\n",
    "# map to label names\n",
    "id2label = {0: \"No narrative\", 1: \"narrative\"}\n",
    "test_results_df[\"true_label_name\"] = test_results_df[\"true_label\"].map(id2label)\n",
    "test_results_df[\"predicted_label_name\"] = test_results_df[\"predicted_label\"].map(id2label)\n",
    "\n",
    "# Save to CSV\n",
    "test_results_df.to_csv(f\"{save_dir}/test_predictions.csv\", index=False)\n",
    "\n",
    "# Save classification report (precision, recall, f1)\n",
    "report = classification_report(test_labels, test_preds, target_names=list(id2label.values()))\n",
    "with open(f\"{save_dir}/test_classification_report.txt\", \"w\") as f:\n",
    "    f.write(report)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5303d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
