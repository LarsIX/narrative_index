{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cda8ae5a",
   "metadata": {},
   "source": [
    "Notebook used to inspect results of Granger Causality analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a384acae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import math\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "# Get the project root: notebooks/AI_narrative_index\n",
    "root_dir = Path.cwd().parent\n",
    "\n",
    "# Add needed folders to the Python modules search path\n",
    "sys.path.append(str(root_dir / \"src\" / \"scripts\"))\n",
    "sys.path.append(str(root_dir / \"src\" / \"visualizations\"))\n",
    "sys.path.append(str(root_dir / \"src\" / \"modelling\"))\n",
    "\n",
    "# import custom functions\n",
    "#rom plot_granger_causality import plot_aini_lags_by_year, plot_aini_lags_for_year\n",
    "from plot_functions import plot_n_articles_with_extrema_events, plot_stock_growth\n",
    "from construct_tables import df_to_pptx \n",
    "from compute_rejections import compute_rejection_rates_all, add_trading_days_columns, export_rejection_rates_to_pptx_all_tables_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4818a819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define path to variables\n",
    "var_path = root_dir / \"data\" / \"processed\" / \"variables\"\n",
    " \n",
    "# load data (without VIX)\n",
    "gc_c = pd.read_csv(var_path / \"granger_causality_binary.csv\")\n",
    "gc_w0 = pd.read_csv(var_path / \"granger_causality_w0.csv\")\n",
    "gc_w1 = pd.read_csv(var_path / \"granger_causality_w1.csv\")\n",
    "gc_w2 = pd.read_csv(var_path / \"granger_causality_w2.csv\")\n",
    "\n",
    "# merge them together\n",
    "gc_all_results = pd.concat([gc_c, gc_w0, gc_w1, gc_w2], ignore_index=True)\n",
    "\n",
    "# save merged results\n",
    "gc_all_results.to_csv(var_path / \"granger_causality_all.csv\", index=False)\n",
    "\n",
    "# define table path\n",
    "table_path = root_dir / \"reports\" / \"tables\"\n",
    "\n",
    "# Export as HTML for online appendix\n",
    "gc_c.to_html(table_path / \"granger_causality_custom_model.html\", index=False)\n",
    "gc_w0.to_html(table_path / \"granger_causality_w0.html\", index=False)\n",
    "gc_w1.to_html(table_path / \"granger_causality_w1.html\", index=False)\n",
    "gc_w2.to_html(table_path / \"granger_causality_w2.html\", index=False)\n",
    "gc_all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "65e126a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# infer total obs per period\n",
    "\n",
    "# load financial data (limiting factor)\n",
    "fin = pd.read_csv(root_dir / \"data\" / \"raw\" / \"financial\" / \"full_daily_2023_2025.csv\")\n",
    "\n",
    "\n",
    "# ensure datetime\n",
    "fin[\"date\"] = pd.to_datetime(fin[\"Date\"])\n",
    "\n",
    "# reduce to unique trading dates\n",
    "dates = fin[\"date\"].drop_duplicates()\n",
    "\n",
    "# min-max bounds\n",
    "start_all = pd.Timestamp(\"2023-04-01\")\n",
    "end_all   = pd.Timestamp(\"2025-06-16\")\n",
    "\n",
    "# masks for periods\n",
    "mask_all        = (dates >= start_all) & (dates <= end_all)\n",
    "mask_2023       = (dates >= \"2023-04-01\") & (dates <= \"2023-12-31\")\n",
    "mask_2024       = (dates.dt.year == 2024)\n",
    "mask_2025       = (dates >= \"2025-01-01\") & (dates <= \"2025-06-16\")\n",
    "mask_2023_2024  = (dates >= \"2023-04-01\") & (dates <= \"2024-12-31\")\n",
    "mask_2024_2025  = (dates >= \"2024-01-01\") & (dates <= \"2025-06-16\")\n",
    "\n",
    "# counts of unique dates\n",
    "counts = {\n",
    "    \"All_2023-04-01_to_2025-06-16\": dates.loc[mask_all].nunique(),\n",
    "    \"2023_after_03-31\":             dates.loc[mask_2023].nunique(),\n",
    "    \"2024_full\":                    dates.loc[mask_2024].nunique(),\n",
    "    \"2025_to_06-16\":                dates.loc[mask_2025].nunique(),\n",
    "    \"Span_2023-2024\":               dates.loc[mask_2023_2024].nunique(),\n",
    "    \"Span_2024-2025\":               dates.loc[mask_2024_2025].nunique(),\n",
    "}\n",
    "\n",
    "print(pd.Series(counts, name=\"n_unique_dates\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bde6de3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Focus only on AINI → Returns direction\n",
    "a2r = gc_all_results[gc_all_results[\"Direction\"].str.contains(\"AINI_to_RET\", case=False)].copy()\n",
    "\n",
    "# Make sure Year and Ticker are strings\n",
    "a2r[\"Year\"] = a2r[\"Year\"].astype(str)\n",
    "a2r[\"Ticker\"] = a2r[\"Ticker\"].astype(str)\n",
    "\n",
    "# Convert bootstrap rejection flag to boolean\n",
    "a2r[\"rej_bh_boot\"] = a2r[\"BH_reject_F\"].astype(bool)\n",
    "a2r[\"rej_bh_hc\"] = a2r[\"BH_reject_F_HC3\"].astype(bool)\n",
    "\n",
    "# Both-method significance = true if both are true\n",
    "a2r[\"rej_both\"] = a2r[\"rej_bh_boot\"] & a2r[\"rej_bh_hc\"]\n",
    "\n",
    "# Total number of models tested\n",
    "total = a2r[\"rej_both\"].count()\n",
    "\n",
    "# Number of rejections (both bootstrap + HC3 significant)\n",
    "n_reject = a2r[\"rej_both\"].sum()\n",
    "\n",
    "# Rejection rate\n",
    "rejection_rate = n_reject / total * 100\n",
    "\n",
    "print(f\"Total models: {total}\")\n",
    "print(f\"Both-method rejections: {n_reject}\")\n",
    "print(f\"Rejection rate: {rejection_rate:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8b80e432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Focus only on returns → AINI direction\n",
    "r2a = gc_all_results[gc_all_results[\"Direction\"].str.contains(\"RET_to_AINI\", case=False)].copy()\n",
    "\n",
    "# Make sure Year and Ticker are strings\n",
    "r2a[\"Year\"] = r2a[\"Year\"].astype(str)\n",
    "r2a[\"Ticker\"] = r2a[\"Ticker\"].astype(str)\n",
    "\n",
    "# Convert bootstrap rejection flag to boolean\n",
    "r2a[\"rej_bh_boot\"] = r2a[\"BH_reject_F\"].astype(bool)\n",
    "r2a[\"rej_bh_hc\"] = r2a[\"BH_reject_F_HC3\"].astype(bool)\n",
    "\n",
    "# Both-method significance = true if both are true\n",
    "r2a[\"rej_both\"] = r2a[\"rej_bh_boot\"] & r2a[\"rej_bh_hc\"]\n",
    "\n",
    "# Total number of models tested\n",
    "total = r2a[\"rej_both\"].count()\n",
    "\n",
    "# Number of rejections (both bootstrap + HC3 significant)\n",
    "n_reject = r2a[\"rej_both\"].sum()\n",
    "\n",
    "# Rejection rate\n",
    "rejection_rate = n_reject / total * 100\n",
    "\n",
    "print(f\"Total models: {total}\")\n",
    "print(f\"Both-method rejections: {n_reject}\")\n",
    "print(f\"Rejection rate: {rejection_rate:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "32648482",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculate rejection rate by Year\n",
    "by_year = (\n",
    "    a2r.groupby(\"Year\")[\"rej_both\"]\n",
    "       .agg([\"sum\",\"count\"])\n",
    "       .assign(rate=lambda x: 100 * x[\"sum\"] / x[\"count\"])\n",
    "       .sort_values(\"rate\", ascending=False)\n",
    ")\n",
    "\n",
    "print(\"By Year (both-method rejection rate):\")\n",
    "print(by_year)\n",
    "\n",
    "# By Ticker (both-method rejection rate)\n",
    "by_ticker = (\n",
    "    a2r.groupby(\"Ticker\")[\"rej_both\"]\n",
    "       .agg([\"sum\",\"count\"])\n",
    "       .assign(rate=lambda x: 100 * x[\"sum\"] / x[\"count\"])\n",
    "       .sort_values(\"rate\", ascending=False)\n",
    ")\n",
    "\n",
    "print(\"\\nBy Ticker (both-method rejection rate):\")\n",
    "print(by_ticker.head(8))\n",
    "\n",
    "for idx, row in by_year.iterrows():\n",
    "    print(f\"{idx}: {row['rate']:.2f}%\")\n",
    "\n",
    "for idx, row in by_ticker.head(8).iterrows():\n",
    "    print(f\"{idx}: {row['rate']:.2f}%\")\n",
    "\n",
    "rejection_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5d5bbecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset for p < y 0.1\n",
    "alpha = 0.1\n",
    "\n",
    "gc_c_sub = gc_c[\n",
    "    (gc_c[\"BH_corr_F_pval\"] < alpha) | (gc_c[\"BH_corr_F_pval_HC3\"] < alpha)\n",
    "].copy()\n",
    "\n",
    "gc_w0_sub = gc_w0[\n",
    "    (gc_w0[\"BH_corr_F_pval\"] < alpha) | (gc_w0[\"BH_corr_F_pval_HC3\"] < alpha)\n",
    "].copy()\n",
    "\n",
    "gc_w1_sub = gc_w1[\n",
    "    (gc_w1[\"BH_corr_F_pval\"] < alpha) | (gc_w1[\"BH_corr_F_pval_HC3\"] < alpha)\n",
    "].copy()\n",
    "\n",
    "gc_w2_sub = gc_w2[\n",
    "    (gc_w2[\"BH_corr_F_pval\"] < alpha) | (gc_w2[\"BH_corr_F_pval_HC3\"] < alpha)\n",
    "].copy()\n",
    "\n",
    "dfs = [gc_c_sub,gc_w0_sub,gc_w1_sub,gc_w2_sub]\n",
    "gc_w1_sub.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9b653ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"custom\", \"w0\", \"w1\", \"w2\"]  # same order as dfs\n",
    "\n",
    "# Collumns to drop in thesis-ready table\n",
    "drop_cols = [\n",
    "    \"p_x\",\"N_boot\",\"N_obs\",\"N_boot_valid\",\"F_stat\",\"df_den\",\n",
    "    \"Original_F_pval\",\"Empirical_F_pval\",\"r2_u\",\"BH_reject_F\",\"BH_reject_F_HC3\"\n",
    "]\n",
    "\n",
    "cleaned = []\n",
    "\n",
    "# iterate over dfs to create subsets by direction\n",
    "for name, df in zip(labels, dfs):\n",
    "    d = df.drop(columns=[c for c in drop_cols if c in df.columns], errors=\"ignore\")\n",
    "    id_cols = [c for c in [\"Ticker\",\"AINI_variant\",\"Year\",\"Direction\",\"BH_corr_F_pval\",\"BH_corr_F_pval_HC3\",\"adj_r2_u\"] if c in d.columns]\n",
    "\n",
    "    a2r = d.loc[d[\"Direction\"]==\"AINI_to_RET\", id_cols + [c for c in d.columns if c.startswith(\"A2R_beta_\")]].copy()\n",
    "    r2a = d.loc[d[\"Direction\"]==\"RET_to_AINI\", id_cols + [c for c in d.columns if c.startswith(\"R2A_beta_\")]].copy()\n",
    "    \n",
    "    # tag which df it came from\n",
    "    a2r[\"Model\"] = name   \n",
    "    r2a[\"Model\"] = name\n",
    "\n",
    "    cleaned.append({\"Model\": name, \"A2R\": a2r, \"R2A\": r2a})\n",
    "\n",
    "# combined frames with the tag:\n",
    "a2r_all = pd.concat([x[\"A2R\"] for x in cleaned], ignore_index=True)\n",
    "r2a_all = pd.concat([x[\"R2A\"] for x in cleaned], ignore_index=True)\n",
    "a2r_all_sort = a2r_all.sort_values([\"Ticker\",\"Year\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cb29b079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# investigate main findings\n",
    "a2r_all.sort_values(\"adj_r2_u\",ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "70cd584b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# investigate potential dependency r2 & beta\n",
    "a2r_all[\"adj_r2_u\"].corr(a2r_all[\"A2R_beta_ret_lag1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e0915183",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_group_tickers = (\n",
    "    a2r_all_sort\n",
    "    .groupby([\"Ticker\", \"Year\"])\n",
    "    .size()\n",
    "    .reset_index(name=\"n_measures\")\n",
    ")\n",
    "\n",
    "model_group_tickers[\"Ticker\"] = model_group_tickers[\"Ticker\"].replace({\"TSM\": \"TSMC\"})\n",
    "model_group_tickers[\"Year\"] = model_group_tickers[\"Year\"].replace({\"2023_24\": \"2023-2024\"})\n",
    "model_group_tickers[\"Year\"] = model_group_tickers[\"Year\"].replace({\"2024_25\": \"2024-2025\"})\n",
    "model_group_tickers[\"Year\"] = model_group_tickers[\"Year\"].replace({\"2023_24_25\": \"2023-2025\"})\n",
    "\n",
    "\n",
    "plt.figure(figsize=(14, 7), dpi=300)\n",
    "ax = sns.barplot(data=model_group_tickers, x=\"Ticker\", y=\"n_measures\", hue=\"Year\", dodge=True)\n",
    "ax.set_title(\"Number of Significant Measures per Ticker and Year\", fontsize=14)\n",
    "ax.set_xlabel(\"Ticker\", fontsize=12)\n",
    "ax.set_ylabel(\"n_measures\", fontsize=12)\n",
    "ax.tick_params(axis=\"x\", rotation=90)\n",
    "ax.legend(title=\"Year\", fontsize=10, title_fontsize=11, loc=\"best\")\n",
    "plt.tight_layout()\n",
    "\n",
    "out_path = root_dir / \"reports\" / \"figures\" / \"significant_measures_year_ticker_nocontrol_gc.png\"\n",
    "plt.savefig(out_path, dpi=300, bbox_inches=\"tight\")\n",
    "plt.close()\n",
    "a2r_all_sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3ebcd22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_group_variant = (\n",
    "    a2r_all_sort\n",
    "    .groupby([\"AINI_variant\", \"Year\"])\n",
    "    .size()\n",
    "    .reset_index(name=\"n_variants\")\n",
    ")\n",
    "\n",
    "model_group_variant[\"Year\"] = model_group_variant[\"Year\"].replace({\"2023_24\": \"2023-2024\"})\n",
    "model_group_variant[\"Year\"] = model_group_variant[\"Year\"].replace({\"2024_25\": \"2024-2025\"})\n",
    "model_group_variant[\"Year\"] = model_group_variant[\"Year\"].replace({\"2023_24_25\": \"2023-2025\"})\n",
    "\n",
    "plt.figure(figsize=(14, 7), dpi=300)\n",
    "ax = sns.barplot(data=model_group_variant, x=\"AINI_variant\", y=\"n_variants\", hue=\"Year\", dodge=True)\n",
    "ax.set_title(\"Number of Significant AINI Variants per Year\", fontsize=14)\n",
    "ax.set_xlabel(\"Ticker\", fontsize=12)\n",
    "ax.set_ylabel(\"n_measures\", fontsize=12)\n",
    "ax.tick_params(axis=\"x\", rotation=90)\n",
    "ax.legend(title=\"Year\", fontsize=10, title_fontsize=11, loc=\"best\")\n",
    "plt.tight_layout()\n",
    "\n",
    "out_path = root_dir / \"reports\" / \"figures\" / \"significant_measures_year_variant_nocontrol_gc.png\"\n",
    "plt.savefig(out_path, dpi=300, bbox_inches=\"tight\")\n",
    "plt.close()\n",
    "model_group_variant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d1b31a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find relevant tickers\n",
    "relevant_tickers = set(model_group_tickers.Ticker)\n",
    "\n",
    "# find all tickers\n",
    "all_tickers = set(gc_w0.Ticker)\n",
    "\n",
    "# ticker without significant results\n",
    "ins_tickers = all_tickers - relevant_tickers\n",
    "ins_tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4289b1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean for reporting\n",
    "\n",
    "# rename \n",
    "rename_dict = {\n",
    "    \"AINI_variant\": \"AINI Variant\",\n",
    "    \"BH_corr_F_pval\": \"BH-corr. F (Bootstrap)\",\n",
    "    \"BH_corr_F_pval_HC3\": \"BH-corr. F (Analytic HC3)\",\n",
    "    \"adj_r2_u\": \"Adj. R²\",\n",
    "    \"A2R_beta_ret_lag1\": \"β₁\",\n",
    "    \"A2R_beta_x_lag1\": \"γ₁\",\n",
    "    \"A2R_beta_x_lag2\": \"γ₂\",\n",
    "    \"A2R_beta_x_lag3\": \"γ₃\",\n",
    "}\n",
    "\n",
    "a2r_all_sort = a2r_all_sort.rename(columns=rename_dict)\n",
    "\n",
    "# drop Direction\n",
    "a2r_all_sort = a2r_all_sort.drop(columns=[\"Direction\"], errors=\"ignore\")\n",
    "\n",
    "# final reporting order\n",
    "order = [\n",
    "    \"Model\",\n",
    "    \"Ticker\",\n",
    "    \"AINI Variant\",\n",
    "    \"Year\",\n",
    "    \"β₁\", \"γ₁\",\n",
    "    \"γ₂\",\n",
    "    \"γ₃\",\n",
    "    \"BH-corr. F (Bootstrap)\",\n",
    "    \"BH-corr. F (Analytic HC3)\",\n",
    "    \"Adj. R²\",\n",
    "]\n",
    "\n",
    "a2r_all_sort = a2r_all_sort[order]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d249f01",
   "metadata": {},
   "source": [
    "Controlled for VIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d6d4f724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data, controlled for log growth of the VIX\n",
    "gc_c_VIX = pd.read_csv(var_path / \"granger_causality_log_growth_VIX_binary.csv\")\n",
    "gc_w0_VIX = pd.read_csv(var_path / \"granger_causality_log_growth_VIX_w0.csv\")\n",
    "gc_w1_VIX = pd.read_csv(var_path / \"granger_causality_log_growth_VIX_w1.csv\")\n",
    "gc_w2_VIX = pd.read_csv(var_path / \"granger_causality_log_growth_VIX_w2.csv\")\n",
    "\n",
    "# concat\n",
    "gc_all_results_VIX = pd.concat([gc_c_VIX,gc_w0_VIX,gc_w1_VIX,gc_w2_VIX], ignore_index=True)\n",
    "\n",
    "# save merged results\n",
    "gc_all_results_VIX.to_csv(var_path / \"granger_causality_VIX_all.csv\", index=False)\n",
    "\n",
    "# Export as HTML for online appendix\n",
    "gc_c_VIX.to_html(table_path / \"granger_causality_VIX_custom_model.html\", index=False)\n",
    "gc_w0_VIX.to_html(table_path / \"granger_causality_VIX_w0.html\", index=False)\n",
    "gc_w1_VIX.to_html(table_path / \"granger_causality_VIX_w1.html\", index=False)\n",
    "gc_w2_VIX.to_html(table_path / \"granger_causality_VIX_w2.html\", index=False)\n",
    "gc_c_VIX.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "44953aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Focus only on AINI → Returns direction\n",
    "a2r_VIX = gc_all_results_VIX[gc_all_results_VIX[\"Direction\"].str.contains(\"AINI_to_RET\", case=False)].copy()\n",
    "\n",
    "# Make sure Year and Ticker are strings\n",
    "a2r_VIX[\"Year\"] = a2r_VIX[\"Year\"].astype(str)\n",
    "a2r_VIX[\"Ticker\"] = a2r_VIX[\"Ticker\"].astype(str)\n",
    "\n",
    "# Convert bootstrap rejection flag to boolean\n",
    "a2r_VIX[\"rej_bh_boot\"] = a2r_VIX[\"BH_reject_F\"].astype(bool)\n",
    "a2r_VIX[\"rej_bh_hc\"] = a2r_VIX[\"BH_reject_F_HC3\"].astype(bool)\n",
    "\n",
    "# Both-method significance = true if both are true\n",
    "a2r_VIX[\"rej_both\"] = a2r_VIX[\"rej_bh_boot\"] & a2r_VIX[\"rej_bh_hc\"]\n",
    "\n",
    "# Total number of models tested\n",
    "total = a2r_VIX[\"rej_both\"].count()\n",
    "\n",
    "# Number of rejections (both bootstrap + HC3 significant)\n",
    "n_reject = a2r_VIX[\"rej_both\"].sum()\n",
    "\n",
    "# Rejection rate\n",
    "rejection_rate = n_reject / total * 100\n",
    "\n",
    "print(f\"Total models: {total}\")\n",
    "print(f\"Both-method rejections: {n_reject}\")\n",
    "print(f\"Rejection rate: {rejection_rate:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f458ac",
   "metadata": {},
   "source": [
    "Create PPT for rejection rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9e27882a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All methods (boot, HC3, both), tables only + Trading days\n",
    "rates = compute_rejection_rates_all(gc_all_results_VIX, direction_substr=\"AINI_to_RET\")\n",
    "rates_with_days = add_trading_days_columns(rates)\n",
    "\n",
    "ppt = export_rejection_rates_to_pptx_all_tables_only(\n",
    "    rates_with_days,\n",
    "    outpath=table_path / \"rejection_rates_all_methods_VIX.pptx\",\n",
    "    top_tickers=15\n",
    ")\n",
    "print(\"Saved PPT:\", ppt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9ce78b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract all aini -> return Ticker, Year pairs\n",
    "gc_all_results_VIX_a2r = gc_all_results_VIX[gc_all_results_VIX[\"Direction\"] == \"AINI_to_RET\"]\n",
    "gc_all_results_VIX_a2r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4a35750d",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"custom\", \"w0\", \"w1\", \"w2\"]  # same order as dfs\n",
    "\n",
    "# Collumns to drop in thesis-ready table\n",
    "drop_cols = [\n",
    "    \"p_x\",\"N_boot\",\"N_obs\",\"N_boot_valid\",\"F_stat\",\"df_den\",\n",
    "    \"Original_F_pval\",\"Empirical_F_pval\",\"r2_u\",\"BH_reject_F\",\"BH_reject_F_HC3\"\n",
    "]\n",
    "\n",
    "cleaned = []\n",
    "\n",
    "# iterate over dfs to create subsets by direction\n",
    "for name, df in zip(labels, dfs):\n",
    "    d = df.drop(columns=[c for c in drop_cols if c in df.columns], errors=\"ignore\")\n",
    "    id_cols = [c for c in [\"Ticker\",\"AINI_variant\",\"Year\",\"Direction\",\"BH_corr_F_pval\",\"BH_corr_F_pval_HC3\",\"adj_r2_u\"] if c in d.columns]\n",
    "\n",
    "    a2r_VIX = d.loc[d[\"Direction\"]==\"AINI_to_RET\", id_cols + [c for c in d.columns if c.startswith(\"A2R_beta_\")]].copy()\n",
    "    r2a_VIX = d.loc[d[\"Direction\"]==\"RET_to_AINI\", id_cols + [c for c in d.columns if c.startswith(\"R2A_beta_\")]].copy()\n",
    "    \n",
    "    # tag which df it came from\n",
    "    a2r_VIX[\"Model\"] = name   \n",
    "    r2a_VIX[\"Model\"] = name\n",
    "\n",
    "    cleaned.append({\"Model\": name, \"A2R\": a2r_VIX, \"R2A\": r2a_VIX})\n",
    "\n",
    "# combined frames with the tag:\n",
    "a2r_all_VIX = pd.concat([x[\"A2R\"] for x in cleaned], ignore_index=True)\n",
    "r2a_all_VIX = pd.concat([x[\"R2A\"] for x in cleaned], ignore_index=True)\n",
    "a2r_all_sort_VIX = a2r_all.sort_values([\"Ticker\",\"Year\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4a7aa61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigate correlation of R2 & betas\n",
    "a2r_all_sort_VIX.sort_values(\"adj_r2_u\",ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "63fb3a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "a2r_all_sort_VIX.adj_r2_u.corr(a2r_all_sort_VIX.A2R_beta_ret_lag1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "de4b7a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset for p < y 0.1\n",
    "alpha = 0.1\n",
    "\n",
    "gc_c_VIX_sub = gc_c_VIX[(gc_c_VIX[\"BH_corr_F_pval\"] < alpha) | (gc_c_VIX[\"BH_corr_F_pval_HC3\"] < alpha)].copy()\n",
    "gc_w0_VIX_sub = gc_w0_VIX[(gc_w0_VIX[\"BH_corr_F_pval\"] < alpha) | (gc_w0_VIX[\"BH_corr_F_pval_HC3\"] < alpha)].copy()\n",
    "gc_w1_VIX_sub = gc_w1_VIX[(gc_w1_VIX[\"BH_corr_F_pval\"] < alpha) | (gc_w1_VIX[\"BH_corr_F_pval_HC3\"] < alpha)].copy()\n",
    "gc_w2_VIX_sub = gc_w2_VIX[(gc_w2_VIX[\"BH_corr_F_pval\"] < alpha) | (gc_w2_VIX[\"BH_corr_F_pval_HC3\"] < alpha)].copy()\n",
    "\n",
    "dfs_VIX = [gc_c_VIX_sub, gc_w0_VIX_sub, gc_w1_VIX_sub, gc_w2_VIX_sub]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d1ed0826",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"custom\", \"w0\", \"w1\", \"w2\"]  \n",
    "\n",
    "# Columns to drop in thesis-ready table\n",
    "drop_cols = [\n",
    "    \"p_x\",\"N_boot\",\"N_obs\",\"N_boot_valid\",\"F_stat\",\"df_den\",\n",
    "    \"Original_F_pval\",\"Empirical_F_pval\",\"r2_u\",\"BH_reject_F\",\"BH_reject_F_HC3\"\n",
    "]\n",
    "\n",
    "cleaned_VIX = []\n",
    "\n",
    "# iterate over dfs_VIX to create subsets by direction\n",
    "for name, df in zip(labels, dfs_VIX):\n",
    "    d = df.drop(columns=[c for c in drop_cols if c in df.columns], errors=\"ignore\")\n",
    "    id_cols = [c for c in [\n",
    "        \"Ticker\",\"AINI_variant\",\"Year\",\"Direction\",\n",
    "        \"BH_corr_F_pval\",\"BH_corr_F_pval_HC3\",\"adj_r2_u\"\n",
    "    ] if c in d.columns]\n",
    "\n",
    "    a2r_VIX = d.loc[d[\"Direction\"]==\"AINI_to_RET\", id_cols + [c for c in d.columns if c.startswith(\"A2R_beta_\")]].copy()\n",
    "    r2a_VIX = d.loc[d[\"Direction\"]==\"RET_to_AINI\", id_cols + [c for c in d.columns if c.startswith(\"R2A_beta_\")]].copy()\n",
    "    \n",
    "    # tag which df it came from\n",
    "    a2r_VIX[\"Model\"] = name\n",
    "    r2a_VIX[\"Model\"] = name\n",
    "\n",
    "    cleaned_VIX.append({\"Model\": name, \"A2R\": a2r_VIX, \"R2A\": r2a_VIX})\n",
    "\n",
    "# Optional combined frames with the tag:\n",
    "a2r_all_VIX = pd.concat([x[\"A2R\"] for x in cleaned_VIX], ignore_index=True)\n",
    "r2a_all_VIX = pd.concat([x[\"R2A\"] for x in cleaned_VIX], ignore_index=True)\n",
    "\n",
    "# sort for readability\n",
    "a2r_all_sort_VIX = a2r_all_VIX.sort_values([\"Ticker\",\"Year\"])\n",
    "r2a_all_sort_VIX = r2a_all_VIX.sort_values([\"Ticker\",\"Year\"])\n",
    "\n",
    "# check columns\n",
    "print(a2r_all_sort_VIX.columns)\n",
    "a2r_all_sort_VIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a57e5b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# investigate insignificant aini / year pairs\n",
    "\n",
    "# make sure Year is string or int in both\n",
    "a2r_all_sort_VIX[\"Year\"] = a2r_all_sort_VIX[\"Year\"].astype(str)\n",
    "gc_all_results_VIX_a2r[\"Year\"] = gc_all_results_VIX_a2r[\"Year\"].astype(str)\n",
    "\n",
    "# extract pairs from each df\n",
    "pairs_a2r = set(zip(a2r_all_sort_VIX[\"Ticker\"], a2r_all_sort_VIX[\"Year\"]))\n",
    "pairs_gc  = set(zip(gc_all_results_VIX_a2r[\"Ticker\"], gc_all_results_VIX_a2r[\"Year\"]))\n",
    "\n",
    "# intersection\n",
    "no_significance = pairs_gc - pairs_a2r\n",
    "a2r_all_sort_VIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "24477f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_group_tickers_VIX = (\n",
    "    a2r_all_sort_VIX\n",
    "    .groupby([\"Ticker\", \"Year\"])\n",
    "    .size()\n",
    "    .reset_index(name=\"n_measures\")\n",
    ")\n",
    "\n",
    "model_group_tickers_VIX[\"Ticker\"] = model_group_tickers_VIX[\"Ticker\"].replace({\"TSM\": \"TSMC\"})\n",
    "model_group_tickers_VIX[\"Year\"] = model_group_tickers_VIX[\"Year\"].replace({\"2023_24\": \"2023-2024\"})\n",
    "model_group_tickers_VIX[\"Year\"] = model_group_tickers_VIX[\"Year\"].replace({\"2024_25\": \"2024-2025\"})\n",
    "model_group_tickers_VIX[\"Year\"] = model_group_tickers_VIX[\"Year\"].replace({\"2023_24_25\": \"2023-2025\"})\n",
    "\n",
    "\n",
    "plt.figure(figsize=(14, 7), dpi=300)\n",
    "ax = sns.barplot(data=model_group_tickers_VIX, x=\"Ticker\", y=\"n_measures\", hue=\"Year\", dodge=True)\n",
    "ax.set_title(\"Number of significant measures (α = 0.1, both methods, ℓ = 1,2,3) per ticker and year (max = 48)\", fontsize=14)\n",
    "ax.set_xlabel(\"Ticker\", fontsize=12)\n",
    "ax.set_ylabel(\"n_measures\", fontsize=12)\n",
    "ax.tick_params(axis=\"x\", rotation=90)\n",
    "ax.legend(title=\"Year\", fontsize=10, title_fontsize=11, loc=\"best\")\n",
    "plt.tight_layout()\n",
    "\n",
    "out_path = root_dir / \"reports\" / \"figures\" / \"significant_measures_year_ticker_VIX_gc.png\"\n",
    "plt.savefig(out_path, dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "model_group_tickers_VIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195cfeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"AINI_variant\" in a2r_all_sort_VIX.columns:\n",
    "    a2r_all_sort_VIX = a2r_all_sort_VIX.rename({\"AINI_variant\":\"AINI Variant\"}\n",
    ")\n",
    "model_group_variant_VIX = (\n",
    "    a2r_all_sort_VIX\n",
    "    .groupby([\"AINI Variant\", \"Year\"])\n",
    "    .size()\n",
    "    .reset_index(name=\"n_variants\")\n",
    ")\n",
    "\n",
    "model_group_variant_VIX[\"Year\"] = model_group_variant_VIX[\"Year\"].replace({\"2023_24\": \"2023-2024\"})\n",
    "model_group_variant_VIX[\"Year\"] = model_group_variant_VIX[\"Year\"].replace({\"2024_25\": \"2024-2025\"})\n",
    "model_group_variant_VIX[\"Year\"] = model_group_variant_VIX[\"Year\"].replace({\"2023_24_25\": \"2023-2025\"})\n",
    "\n",
    "plt.figure(figsize=(14, 7), dpi=300)\n",
    "ax = sns.barplot(data=model_group_variant_VIX, x=\"AINI Variant\", y=\"n_variants\", hue=\"Year\", dodge=True)\n",
    "ax.set_title(\"Number of significant AINI variants (α = 0.1, both methods, ℓ = 1,2,3) by year (max = 45)\", fontsize=14)\n",
    "ax.set_xlabel(\"\", fontsize=12)\n",
    "ax.set_ylabel(\"n_measures\", fontsize=12)\n",
    "ax.tick_params(axis=\"x\", rotation=0)\n",
    "ax.legend(title=\"Year\", fontsize=10, title_fontsize=11, loc=\"best\")\n",
    "plt.tight_layout()\n",
    "\n",
    "out_path = root_dir / \"reports\" / \"figures\" / \"significant_measures_year_variant_VIX_gc.png\"\n",
    "plt.savefig(out_path, dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c228d11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean for reporting\n",
    "\n",
    "# rename \n",
    "rename_dict = {\n",
    "    \"AINI_variant\": \"AINI Variant\",\n",
    "    \"BH_corr_F_pval\": \"BH-corr. F (Bootstrap)\",\n",
    "    \"BH_corr_F_pval_HC3\": \"BH-corr. F (Analytic HC3)\",\n",
    "    \"adj_r2_u\": \"Adj. R²\",\n",
    "    \"A2R_beta_ret_1\": \"β₁\",\n",
    "    \"A2R_beta_x_1\": \"γ₁\",\n",
    "    \"A2R_beta_ret_2\": \"β₂\",\n",
    "    \"A2R_beta_x_2\": \"γ₂\",\n",
    "    \"A2R_beta_ret_3\": \"β₃\",\n",
    "    \"A2R_beta_x_3\": \"γ₃\",\n",
    "}\n",
    "\n",
    "a2r_all_sort_VIX = a2r_all_sort_VIX.rename(columns=rename_dict)\n",
    "\n",
    "# drop Direction\n",
    "a2r_all_sort_VIX = a2r_all_sort_VIX.drop(columns=[\"Direction\"], errors=\"ignore\")\n",
    "\n",
    "# final reporting order\n",
    "order = [\n",
    "    \"Model\",\n",
    "    \"Ticker\",\n",
    "    \"AINI Variant\",\n",
    "    \"Year\",\n",
    "    \"β₁\", \"β₂\", \"β₃\",\n",
    "    \"γ₁\", \"γ₂\", \"γ₃\",\n",
    "    \"BH-corr. F (Bootstrap)\",\n",
    "    \"BH-corr. F (Analytic HC3)\",\n",
    "    \"Adj. R²\",\n",
    "]\n",
    "\n",
    "# order columns, sort by abs. beta 1\n",
    "a2r_all_sort_VIX = a2r_all_sort_VIX[order].sort_values(\n",
    "    by=\"γ₁\",\n",
    "    key=lambda col: col.abs(),\n",
    "    ascending=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15fecdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# round to 4 decimal\n",
    "cols = ['β₁', 'β₂', 'β₃', 'γ₁', 'γ₂','γ₃','BH-corr. F (Bootstrap)', 'BH-corr. F (Analytic HC3)', 'Adj. R²']\n",
    "a2r_all_sort_VIX_round = a2r_all_sort_VIX.copy()\n",
    "a2r_all_sort_VIX_round[cols] = a2r_all_sort_VIX[cols].apply(lambda x: x.round(4))\n",
    "\n",
    "# beautify\n",
    "a2r_all_sort_VIX_round[\"Year\"].replace({\"_\":\"-\"},inplace=True)\n",
    "a2r_all_sort_VIX_round.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30c9e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- DataFrame ---\n",
    "df = a2r_all_sort_VIX_round.copy()\n",
    "\n",
    "# sort tickers for readability (by median absolute β₁)\n",
    "ticker_order = (\n",
    "    df.groupby(\"Ticker\")[\"γ₁\"]\n",
    "      .apply(lambda x: x.abs().median())\n",
    "      .sort_values(ascending=False)\n",
    "      .index\n",
    "      .tolist()\n",
    ")\n",
    "df[\"Ticker\"] = pd.Categorical(df[\"Ticker\"], categories=ticker_order, ordered=True)\n",
    "df = df.sort_values([\"Ticker\", \"Model\"])\n",
    "\n",
    "# map each Model to a marker shape\n",
    "markers = ['o','s','^','D','P','X','v','<','>']\n",
    "model_list = df[\"Model\"].unique().tolist()\n",
    "model_to_marker = {m: markers[i % len(markers)] for i, m in enumerate(model_list)}\n",
    "\n",
    "# y positions with small offsets so multiple models per ticker don’t overlap\n",
    "base_y = df[\"Ticker\"].cat.codes.values.astype(float)\n",
    "offsets = np.linspace(-0.25, 0.25, num=len(model_list)) if len(model_list) > 1 else [0.0]\n",
    "model_to_offset = {m: offsets[i] for i, m in enumerate(model_list)}\n",
    "y_pos = base_y + df[\"Model\"].map(model_to_offset).values\n",
    "\n",
    "# --- Plot ---\n",
    "fig, ax = plt.subplots(figsize=(10, max(4, 0.35*len(ticker_order)+1)))\n",
    "ax.axvline(0, linestyle=\"--\", color=\"gray\", linewidth=1)\n",
    "\n",
    "for m in model_list:\n",
    "    sub = df[df[\"Model\"] == m]\n",
    "    ax.scatter(\n",
    "        sub[\"γ₁\"], \n",
    "        sub[\"Ticker\"].cat.codes + model_to_offset[m],\n",
    "        marker=model_to_marker[m],\n",
    "        s=70,\n",
    "        label=m\n",
    "    )\n",
    "\n",
    "ax.set_yticks(np.arange(len(ticker_order)))\n",
    "ax.set_yticklabels(ticker_order)\n",
    "ax.set_xlabel(r\"$\\gamma_1$\")\n",
    "ax.set_ylabel(\"Ticker\")\n",
    "ax.set_title(r\"$\\gamma_1$ by Ticker for significant results (α = 0.1, both methods), ℓ = 1,2,3, all periods\")\n",
    "ax.legend(title=\"Model\", frameon=False)\n",
    "plt.tight_layout()\n",
    "plt.savefig(root_dir / \"reports\" / \"figures\" / f\"y1_by_ticker_model_all_periods.png\")\n",
    "plt.show()\n",
    "a2r_all_sort_VIX_round\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34670ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = a2r_all_sort_VIX_round.copy()\n",
    "\n",
    "gamma_cols = ['γ₁','γ₂','γ₃']\n",
    "df[gamma_cols] = df[gamma_cols].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "EPS = 0.0   # set e.g. 1e-12 to treat near-zero as zero\n",
    "DROP_ZEROS = False  # single switch for both overall and by-ticker\n",
    "\n",
    "def _sign_with_eps(x: pd.Series, eps: float = EPS) -> pd.Series:\n",
    "    z = x.copy()\n",
    "    z = z.where(~z.between(-eps, eps), 0.0)\n",
    "    return np.sign(z)\n",
    "\n",
    "def flip_stats(a: pd.Series, b: pd.Series, drop_zeros: bool = DROP_ZEROS) -> pd.DataFrame:\n",
    "    s1, s2 = _sign_with_eps(a), _sign_with_eps(b)\n",
    "    valid = (~a.isna()) & (~b.isna())\n",
    "    if drop_zeros:\n",
    "        valid &= (s1 != 0) & (s2 != 0)\n",
    "    flips = (s1 * s2 < 0) & valid\n",
    "    n_flips = int(flips.sum())\n",
    "    n_valid = int(valid.sum())\n",
    "    rate = n_flips / n_valid if n_valid > 0 else np.nan\n",
    "    return pd.DataFrame({'pair':[f'{a.name} vs {b.name}'],\n",
    "                         'n_flips':[n_flips],\n",
    "                         'n_valid':[n_valid],\n",
    "                         'flip_rate':[rate]})\n",
    "\n",
    "# --- Overall counts (consistent with DROP_ZEROS) ---\n",
    "overall = pd.concat([\n",
    "    flip_stats(df['γ₁'], df['γ₂']),\n",
    "    flip_stats(df['γ₁'], df['γ₃']),\n",
    "    flip_stats(df['γ₂'], df['γ₃'])\n",
    "], ignore_index=True)\n",
    "\n",
    "label = \"strict, zeros excluded\" if DROP_ZEROS else \"zeros included\"\n",
    "print(f\"Overall sign flips ({label}):\")\n",
    "print(overall)\n",
    "\n",
    "# --- By Ticker (consistent with DROP_ZEROS) ---\n",
    "def flip_by_group(group, a_name, b_name, drop_zeros: bool = DROP_ZEROS):\n",
    "    a, b = group[a_name], group[b_name]\n",
    "    s1, s2 = _sign_with_eps(a), _sign_with_eps(b)\n",
    "    valid = (~a.isna()) & (~b.isna())\n",
    "    if drop_zeros:\n",
    "        valid &= (s1 != 0) & (s2 != 0)\n",
    "    flips = (s1 * s2 < 0) & valid\n",
    "    return pd.Series({\n",
    "        'n_flips': int(flips.sum()),\n",
    "        'n_valid': int(valid.sum()),\n",
    "        'flip_rate': (int(flips.sum()) / int(valid.sum())) if int(valid.sum()) > 0 else np.nan\n",
    "    })\n",
    "\n",
    "by_ticker = []\n",
    "for a, b in [('γ₁','γ₂')]:  # add ('γ₁','γ₃'), ('γ₂','γ₃') if needed\n",
    "    out = (df.groupby('Ticker', dropna=False)\n",
    "             .apply(lambda g: flip_by_group(g, a, b, DROP_ZEROS))\n",
    "             .reset_index())\n",
    "    out.insert(1, 'pair', f'{a} vs {b}')\n",
    "    by_ticker.append(out)\n",
    "by_ticker = pd.concat(by_ticker, ignore_index=True)\n",
    "\n",
    "print(f\"\\nSign flips by Ticker ({label}):\")\n",
    "print(by_ticker)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92d5875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify major peaks\n",
    "majors = list()\n",
    "regressors = ['γ₁','γ₂','γ₃']\n",
    "\n",
    "majors = a2r_all_sort_VIX_round[\n",
    "    (a2r_all_sort_VIX_round[regressors] > 0.15) |\n",
    "    (a2r_all_sort_VIX_round[regressors] < -0.15)\n",
    "].dropna(how=\"all\", subset=regressors)\n",
    "\n",
    "majors_idx = majors.index\n",
    "majors_df = a2r_all_sort_VIX_round.iloc[majors_idx]\n",
    "\n",
    "frag_large = majors_df.shape[0] /  a2r_all_sort_VIX_round.shape[0]\n",
    "\n",
    "#rows with at least one regressor < -0.15\n",
    "neg = a2r_all_sort_VIX_round.loc[\n",
    "    (a2r_all_sort_VIX_round[regressors] < -0.15).any(axis=1),\n",
    "    [\"AINI Variant\", \"Year\", \"Ticker\"] + regressors\n",
    "].drop_duplicates()\n",
    "\n",
    "# rows with at least one regressor > 0.15\n",
    "pos = a2r_all_sort_VIX_round.loc[\n",
    "    (a2r_all_sort_VIX_round[regressors] > 0.15).any(axis=1),\n",
    "    [\"AINI Variant\", \"Year\", \"Ticker\"] + regressors\n",
    "].drop_duplicates()\n",
    "\n",
    "print(\"Negative extremes (< -0.15):\")\n",
    "print(neg.to_string(index=False))\n",
    "\n",
    "print(\"\\nPositive extremes (> 0.15):\")\n",
    "print(pos.to_string(index=False))\n",
    "print(f\"\\Total of extrema {majors.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc23ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- DataFrame ---\n",
    "df = a2r_all_sort_VIX_round.copy()\n",
    "\n",
    "# sort tickers for readability (by median absolute β₁)\n",
    "ticker_order = (\n",
    "    df.groupby(\"Ticker\")[\"β₁\"]\n",
    "      .apply(lambda x: x.abs().median())\n",
    "      .sort_values(ascending=False)\n",
    "      .index\n",
    "      .tolist()\n",
    ")\n",
    "df[\"Ticker\"] = pd.Categorical(df[\"Ticker\"], categories=ticker_order, ordered=True)\n",
    "df = df.sort_values([\"Ticker\", \"Model\"])\n",
    "\n",
    "# map each Model to a marker shape\n",
    "markers = ['o','s','^','D','P','X','v','<','>']\n",
    "model_list = df[\"Model\"].unique().tolist()\n",
    "model_to_marker = {m: markers[i % len(markers)] for i, m in enumerate(model_list)}\n",
    "\n",
    "# y positions with small offsets so multiple models per ticker don’t overlap\n",
    "base_y = df[\"Ticker\"].cat.codes.values.astype(float)\n",
    "offsets = np.linspace(-0.25, 0.25, num=len(model_list)) if len(model_list) > 1 else [0.0]\n",
    "model_to_offset = {m: offsets[i] for i, m in enumerate(model_list)}\n",
    "y_pos = base_y + df[\"Model\"].map(model_to_offset).values\n",
    "\n",
    "# --- Plot ---\n",
    "fig, ax = plt.subplots(figsize=(10, max(4, 0.35*len(ticker_order)+1)))\n",
    "ax.axvline(0, linestyle=\"--\", color=\"gray\", linewidth=1)\n",
    "\n",
    "for m in model_list:\n",
    "    sub = df[df[\"Model\"] == m]\n",
    "    ax.scatter(\n",
    "        sub[\"β₁\"], \n",
    "        sub[\"Ticker\"].cat.codes + model_to_offset[m],\n",
    "        marker=model_to_marker[m],\n",
    "        s=70,\n",
    "        label=m\n",
    "    )\n",
    "\n",
    "ax.set_yticks(np.arange(len(ticker_order)))\n",
    "ax.set_yticklabels(ticker_order)\n",
    "ax.set_xlabel(r\"$\\beta_1$\")\n",
    "ax.set_ylabel(\"Ticker\")\n",
    "ax.set_title(r\"$\\beta_1$ by Ticker (markers = Model)\")\n",
    "ax.legend(title=\"Model\", frameon=False)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a6204f",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = a2r_all_sort_VIX_round.copy()\n",
    "\n",
    "# ensure numeric γ₁ (for ordering)\n",
    "base[\"γ₁\"] = pd.to_numeric(base[\"γ₁\"], errors=\"coerce\")\n",
    "\n",
    "for yr in sorted(base[\"Year\"].dropna().unique()):\n",
    "    df = base[base[\"Year\"] == yr].copy()\n",
    "\n",
    "    # sort tickers by median |γ₁| for readability\n",
    "    ticker_order = (\n",
    "        df.groupby(\"Ticker\")[\"γ₁\"]\n",
    "          .apply(lambda x: x.abs().median())\n",
    "          .sort_values(ascending=False)\n",
    "          .index\n",
    "          .tolist()\n",
    "    )\n",
    "\n",
    "    # categorical order\n",
    "    df[\"Ticker\"] = pd.Categorical(df[\"Ticker\"], categories=ticker_order, ordered=True)\n",
    "    df = df.sort_values([\"Ticker\", \"Model\"])\n",
    "\n",
    "    # map Model -> marker\n",
    "    markers = ['o','s','^','D','P','X','v','<','>']\n",
    "    model_list = df[\"Model\"].dropna().unique().tolist()\n",
    "    model_to_marker = {m: markers[i % len(markers)] for i, m in enumerate(model_list)}\n",
    "\n",
    "    # y offsets so models for same ticker don't overlap\n",
    "    offsets = np.linspace(-0.25, 0.25, num=len(model_list)) if len(model_list) > 1 else [0.0]\n",
    "    model_to_offset = {m: offsets[i] for i, m in enumerate(model_list)}\n",
    "\n",
    "    # plot per year\n",
    "    fig, ax = plt.subplots(figsize=(10, max(4, 0.35*len(ticker_order)+1)))\n",
    "    ax.axvline(0, linestyle=\"--\", color=\"gray\", linewidth=1)\n",
    "\n",
    "\n",
    "    # ensure markers\n",
    "    for m in model_list:\n",
    "        sub = df[df[\"Model\"] == m]\n",
    "        ax.scatter(\n",
    "            sub[\"γ₁\"],\n",
    "            sub[\"Ticker\"].cat.codes + model_to_offset[m],\n",
    "            marker=model_to_marker[m],\n",
    "            s=70,\n",
    "            label=m\n",
    "        )\n",
    "\n",
    "    # axes, labels, legend outside the model loop\n",
    "    ax.set_yticks(np.arange(len(ticker_order)))\n",
    "    ax.set_yticklabels(ticker_order)\n",
    "    ax.set_xlabel(r\"$\\gamma_1$\")\n",
    "    ax.set_ylabel(\"Ticker\")\n",
    "    ax.set_title(rf\"$\\gamma_1$ by Ticker (markers = Model), Year = {yr}\")\n",
    "    ax.legend(title=\"Model\", frameon=False)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # save ONCE per year\n",
    "    out_path = root_dir / \"reports\" / \"figures\" / f\"year_{yr}_gc_vix_size_by_ticker.png\"\n",
    "    plt.savefig(out_path, dpi=300)\n",
    "    plt.close(fig)\n",
    "    print(f\"Saved figure: {out_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3ff8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppt_path = df_to_pptx(\n",
    "    a2r_all_sort_VIX_round,\n",
    "    outpath=table_path / \"Granger_causality_AINI_VIX.pptx\",\n",
    "    rows_per_slide=7\n",
    ")\n",
    "print(\"Saved PPT:\", ppt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aeb6fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "rounds_col = [ 'β₁', 'β₂', 'β₃', 'γ₁', 'γ₂','γ₃', 'BH-corr. F (Bootstrap)', 'BH-corr. F (Analytic HC3)', 'Adj. R²']\n",
    "majors_df_round = majors_df.copy()\n",
    "majors_df_round[rounds_col] = majors_df[rounds_col].round(4)\n",
    "\n",
    "ppt_path = df_to_pptx(\n",
    "    majors_df_round,\n",
    "    outpath=table_path / \"Granger_causality_AINI_VIX_large_magnitude_results.pptx\",\n",
    "    rows_per_slide=7\n",
    ")\n",
    "print(\"Saved PPT:\", ppt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3789807b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# investigate \n",
    "majors_df_round.groupby(\"Ticker\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03c671b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot stock prices \n",
    "tickers = [\n",
    "    \"AAPL\",\"AIQ\",\"AMD\",\"AMZN\",\"ARKQ\",\n",
    "    \"AVGO\",\"BOTZ\",\"GOOGL\",\"IRBO\",\"META\",\n",
    "    \"MSFT\",\"NVDA\",\"ROBO\",\"TSLA\",\"TSM\"\n",
    "]\n",
    "start = pd.Timestamp(\"2023-04-01\")\n",
    "end   = pd.Timestamp(\"2025-06-16\")\n",
    "\n",
    "# ensure datetime \n",
    "fin[\"date\"] = pd.to_datetime(fin[\"date\"])\n",
    "\n",
    "# filter by date and ticker\n",
    "mask = (fin[\"date\"] >= start) & (fin[\"date\"] <= end)\n",
    "d = fin.loc[mask, [\"date\",\"Ticker\",\"Adj Close\"]].copy()\n",
    "\n",
    "# safety: drop rows without price\n",
    "d = d.dropna(subset=[\"Adj Close\"])\n",
    "\n",
    "# compute global y-limits to keep same y-scale across all plots\n",
    "ymin = d[\"Adj Close\"].min()\n",
    "ymax = d[\"Adj Close\"].max()\n",
    "pad = 0.03 * (ymax - ymin) if ymax > ymin else 1.0\n",
    "ylims = (ymin - pad, ymax + pad)\n",
    "\n",
    "# sort tickers consistently and split into 3 groups of 5\n",
    "tickers_sorted = sorted(tickers)\n",
    "groups = [tickers_sorted[i:i+5] for i in range(0, len(tickers_sorted), 5)]\n",
    "\n",
    "# define fig_path\n",
    "fig_path = root_dir / \"reports\" / \"figures\"\n",
    "\n",
    "# make one figure per group\n",
    "for gi, grp in enumerate(groups, start=1):\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    for t in grp:\n",
    "        sub = d[d[\"Ticker\"] == t].sort_values(\"date\")\n",
    "        if sub.empty:\n",
    "            continue\n",
    "        ax.plot(sub[\"date\"], sub[\"Adj Close\"], linewidth=1.8, label=t)\n",
    "        ax.set_title(f\"Adj Close — Group {gi}: {', '.join(grp)}\")\n",
    "        ax.set_xlabel(\"Date\")\n",
    "        ax.set_ylabel(\"Adj Close\")\n",
    "        ax.set_xlim(start, end)   # same x-scale\n",
    "        ax.set_ylim(*ylims)       # same y-scale\n",
    "        ax.legend(ncol=3, frameon=False, loc=\"upper left\", bbox_to_anchor=(0, 1.02))\n",
    "        fig.autofmt_xdate()\n",
    "        plt.tight_layout()\n",
    "        fig.savefig( fig_path /f\"adj_close_group_{gi}.png\", dpi=300, bbox_inches=\"tight\")\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dec55e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_n_articles_with_extrema_eventstickers = [\"AAPL\",\"AIQ\",\"AMD\",\"AMZN\",\"ARKQ\",\"AVGO\",\"BOTZ\",\"GOOGL\",\"IRBO\",\"META\",\n",
    "           \"MSFT\",\"NVDA\",\"ROBO\",\"TSLA\",\"TSM\"]\n",
    "\n",
    "# df is your DataFrame with the columns you listed\n",
    "plot_stock_growth(\n",
    "    fin,\n",
    "    tickers=plot_n_articles_with_extrema_eventstickers,\n",
    "    start=\"2023-04-01\",\n",
    "    end=\"2025-06-15\",\n",
    "    group_size=5,\n",
    "    base=100.0,\n",
    "    save_dir=fig_path,   \n",
    "    show=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3567ea2b",
   "metadata": {},
   "source": [
    "Controlled for number of articles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4a4786",
   "metadata": {},
   "source": [
    "Create reporting tables for thesis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9c533d",
   "metadata": {},
   "source": [
    "re-perform Granger Causality analysis to include t-stats for lowest AIC/BIC variables"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
