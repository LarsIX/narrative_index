# AI Narrative Index (AINI)

**English version:** [here](https://github.com/LarsIX/narrative_index/blob/main/README%20-%20English.md)
**Finale Thesis:** [here](https://github.com/LarsIX/narrative_index/blob/main/README%20-%20English.md)
---

## Ãœberblick

Dieses Repository dokumentiert die vollstÃ¤ndige Forschungs- und Implementierungspipeline zur Konstruktion des **AI Narrative Index (AINI)** â€” einer Zeitreihe, die misst, wie KÃ¼nstliche Intelligenz (KI) in Finanznachrichten dargestellt wird.  
Nach aktuellem Kenntnisstand handelt es sich um den **ersten technologiespezifischen Hype-Index**, der narrative Aufmerksamkeit und Sentiment gegenÃ¼ber KI quantitativ erfasst.

Das Projekt kombiniert **Transformer-basierte Sprachmodelle**, **Deep Learning** und **Ã¶konometrische Inferenz** in einer **modularen, reproduzierbaren Architektur**.

![Flowchart](https://github.com/user-attachments/assets/1296faff-9172-4a18-af42-16b829f4c823)

*Hinweis: Der Prozessablauf ist in englischer Sprache dargestellt, da die zugrunde liegende Arbeit vollstÃ¤ndig auf Englisch verfasst wurde.*

---

## Forschungsziele

- Entwicklung mehrerer **Transformer-basierter Varianten** des AINI (verschiedene Kontextfenster und FinBERT-Finetuning)
- Quantifizierung narrativer **Hype-Effekte auf FinanzmÃ¤rkte** mittels Granger-KausalitÃ¤t
- Sicherstellung **wissenschaftlicher ValiditÃ¤t** durch Doppelannotation, diagnostische Tests und resampling-basierte Inferenz

---

## Konstruktion des AINI

Der Index kombiniert **menschliche Annotation**, **feingetunte Sprachmodelle** und **lexikonbasierte Methoden**, um KI-bezogene Narrative in Finanztexten zu messen.

### 1. Manuelle Annotation & Feintuning von FinBERT

- Erstellung eines doppelt annotierten Datensatzes zur Identifikation von **KI-relevanten Artikeln**  
- Feintuning eines **FinBERT-Modells** auf dieser Basis zur binÃ¤ren Klassifikation (â€Ã¼ber KIâ€œ / â€nicht Ã¼ber KIâ€œ)  
- Anwendung des Modells auf Artikel des **Wall Street Journal (WSJ, 2023â€“2025)**  
- DurchfÃ¼hrung einer **Sentimentanalyse** ([ProsusAI/finbert](https://huggingface.co/ProsusAI/finbert)) auf erkannte Narrative  
- Normalisierung, Aggregation und exponentielle GlÃ¤ttung der Ergebnisse zu einer **tÃ¤glichen Zeitreihe**

### 2. Lexikonbasierte Snippet-Selektion

- Vorselektion KI-bezogener AbsÃ¤tze durch eine **regelbasierte Keywordsuche**
- Extraktion mehrerer **Kontextfenster** um geflaggte SchlÃ¼sselwÃ¶rter
- Anwendung von FinBERT auf diese Snippets, anschlieÃŸende **Aggregation und GlÃ¤ttung** zu Tageswerten
- Erstellung zusÃ¤tzlicher AINI-Varianten zur Robustheitsanalyse

---

## Statistische Inferenz

Die Wechselwirkungen zwischen Narrativen und Finanzmarktvariablen werden mit **Ã¶konometrischen Verfahren** untersucht.

### StationaritÃ¤tstests
- Augmented Dickey-Fuller (ADF)  
- Phillips-Perron (PP)  
- KPSS  

Alle Zeitreihen wurden auf StationaritÃ¤t geprÃ¼ft und bei Bedarf differenziert.

### Granger-KausalitÃ¤t

Zur Analyse der Richtungseffekte zwischen AINI und Aktienrenditen wird Granger-KausalitÃ¤t verwendet.  
Die Tests basieren auf:

- **Wild Residual Bootstrap** (10.000 Resamples mit Rademacher-Gewichten) â†’ robuste empirische p-Werte  
- **Benjaminiâ€“Hochberg-Korrektur** zur Kontrolle der Fehlerquote bei multiplen Tests  

Beispielhafte Regressionsspezifikation:

![Granger causality](gc_equ_c.png)

Alle Modelle wurden auch in der **Gegenrichtung** (log. Rendite â†’ AINI) geschÃ¤tzt, um RÃ¼ckkopplungseffekte zwischen Markt und Narrativen zu erfassen.

*Kontrollvariablen:* Wachstumsraten tÃ¤glicher Artikelzahlen, S&P 500, SOX-Index.  
*Lag-LÃ¤ngen:* l = Ï âˆˆ {1, 2, 3}

---

## Ergebnisse (Auswahl)

### AI Narrative Index (AINI) â€“ Variantenvergleich
Die Varianten unterscheiden sich in der GrÃ¶ÃŸe des verwendeten Kontextfensters:
wâ‚€ nutzt ausschlieÃŸlich den Satz mit einem KI-SchlÃ¼sselwort (keine Kontextintegration),
wâ‚ erweitert das Fenster bidirektional um einen Satz vor und nach dem Treffer,
wâ‚‚ umfasst zwei SÃ¤tze um den Treffer,
und custom verarbeitet den vollstÃ¤ndigen Artikel (Titel + Haupttext, bis zu 512 Token).
Dadurch steigt mit wachsendem Kontextfenster die semantische Tiefe und narrative KohÃ¤renz der erfassten Textpassagen.
![AINI](aini_means.png)

### Signifikante Effekte nach Asset und Periode
Die nÃ¤chste Abbildung zeigt signifikante Granger-KausalitÃ¤tsergebnisse (AINI â†’ Renditen):

![Signifikante Ergebnisse per Asset](vix_aini_to_ret_sig_counts.png)

### Verteilung der Regressionskoeffizienten
Die Verteilung der Î³-Koeffizienten zeigt die Streuung und Richtung der AINI-Effekte:

![Verteilung der Regressoren](distribution_of_gammas.png)

---

## Zentrale Befunde

**Modellverhalten**
- GrÃ¶ÃŸere Kontextfenster fÃ¼hren tendenziell zu negativeren Sentiments.
- Die FinBERT-Variante erzielt mit einem gewichteten Macro-F1-Score von **0.92** sehr gute Ergebnisse.
- Die lexikonbasierte Variante zeigt vergleichbare Klassifikationsleistung auf dem validierten Datensatz.

**Ã–konomische Ergebnisse**
- Die AINI-Serien (wâ‚€â€“wâ‚‚) sind 2025 nicht stationÃ¤r â†’ mÃ¶gliches Regimewechsel-Signal.
- In Ãœbereinstimmung mit der Effizienzmarkthypothese sind die meisten Regressionen insignifikant.
- FÃ¼r signifikante FÃ¤lle erklÃ¤rt der AINI nur einen kleinen Teil der Gesamtvarianz, erhÃ¶ht jedoch kurzfristig die RenditevolatilitÃ¤t um das 5- bis 35-Fache.
- In der Gegenrichtung (Rendite â†’ AINI) zeigen manche Assets eine starke narrative Reaktion (bis zu 85 % erklÃ¤rte Variation).

**Limitationen**
- BeschrÃ¤nkt auf WSJ-Daten (2023â€“2025)
- Fokus auf wachstumsstarke Assets (z. B. NVIDIA)
- Begrenzter Zeitraum und Stichprobe
- Keine Modellierung nichtlinearer Effekte

---

```text
AI_narrative_index/
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ fetch_data/
â”‚   â”‚   â”œâ”€â”€ load_financial_data.py              # ETL-Modul zum Abruf und Preprocessing von Finanzmarktdaten (APIs, YahooFinance etc.)
â”‚   â”‚   â”œâ”€â”€ wsj_archive_crawler.py              # Web-Crawler fÃ¼r WSJ-Archivseiten (URL-Discovery pro Tag)
â”‚   â”‚   â””â”€â”€ wsj_archive_scraper.py              # Scraper zum Extrahieren kompletter Artikeltexte (Content Harvesting)
â”‚   â”‚
â”‚   â”œâ”€â”€ preprocessing/
â”‚   â”‚   â”œâ”€â”€ clean_database.py                   # Datenbereinigung: Filterung nach Rubriken, TextlÃ¤nge, Duplikaten
â”‚   â”‚   â”œâ”€â”€ corpus_cleaning.py                  # Text-Normalisierung: Entfernt HTML-Artefakte, UI-Reste, Metadaten
â”‚   â”‚   â”œâ”€â”€ reduce_db_for_sentiment.py          # Sampling-Modul: Teilmenge fÃ¼r Sentiment-Labeling extrahieren
â”‚   â”‚   â”œâ”€â”€ combine_article_dbs.py              # Datenaggregation: ZusammenfÃ¼hren mehrerer SQLite-Jahre in ein zentrales CSV
â”‚   â”‚   â”œâ”€â”€ fix_article_ids.py                  # DatenintegritÃ¤t: Sicherstellung eindeutiger Artikel-IDs
â”‚   â”‚   â”œâ”€â”€ section_filtering.py                # Relevanzfilterung: Entfernt irrelevante Themen-Sektionen
â”‚   â”‚   â””â”€â”€ simple_ai_filter.py                 # Keyword-basierte Pre-Selektion KI-relevanter Artikel (Rule-based Tagging)
â”‚   â”‚
â”‚   â”œâ”€â”€ annotation/
â”‚   â”‚   â”œâ”€â”€ comparing_annotations.py            # Inter-Annotator-Agreement & KonfliktauflÃ¶sung
â”‚   â”‚   â””â”€â”€ label_articles.py                   # Interaktive Annotation-UI (Labeling-Pipeline fÃ¼r AI/Hype-Kategorien)
â”‚   â”‚
â”‚   â”œâ”€â”€ modelling/
â”‚   â”‚   â”œâ”€â”€ ai_windows.py                       # Context-Window-Generator: Snippet-Extraction um KI-Begriffe
â”‚   â”‚   â”œâ”€â”€ calculate_summary_statistics.py     # Explorative Statistik & Feature-Diagnostics
â”‚   â”‚   â”œâ”€â”€ compute_extrema.py                  # Ermittlung lokaler Extremwerte der AINI-Features
â”‚   â”‚   â”œâ”€â”€ construct_AINI_variables.py         # Feature-Engineering: Konstruktion & Normalisierung der AINI-Zeitreihen
â”‚   â”‚   â”œâ”€â”€ CustomFinBERT.py                    # Angepasstes FinBERT-Modell mit Class-Weights, Dropout & Layer-Freezing
â”‚   â”‚   â”œâ”€â”€ stationarity_testing.py             # Zeitreihen-Diagnostik: StationaritÃ¤tstests (ADF, PP)
â”‚   â”‚   â”œâ”€â”€ estimate_granger_causality.py       # Kausalinferenz-Pipeline mit Bootstrap-Granger-Tests
â”‚   â”‚   â”œâ”€â”€ estimate_transfer_entropy.py        # Legacy-Modul: KSG-basierte Transfer-Entropie-SchÃ¤tzung
â”‚   â”‚   â”œâ”€â”€ format_te_gc_inputs.py              # Daten-Preprocessing fÃ¼r TE/GC-Module (Lag-Alignment, Normalisierung)
â”‚   â”‚   â”œâ”€â”€ predict_binary_AINI_FinBERT.py      # Inferenz: Klassifikation â€AI vs. Non-AIâ€œ mit FinBERT
â”‚   â”‚   â””â”€â”€ predict_AINI_FinBERT_window.py      # Kontextsensitive Sentiment-Inference (window-basiert)
â”‚   â”‚
â”‚   â”œâ”€â”€ visualizations/
â”‚   â”‚   â”œâ”€â”€ construct_tables.py                 # Tabellarisches Reporting (LaTeX-Export der GC-Resultate)
â”‚   â”‚   â”œâ”€â”€ plot_functions.py                   # Generische Plot-Utilities fÃ¼r Zeitreihen & Sentiment-VerlÃ¤ufe
â”‚   â”‚   â”œâ”€â”€ plot_granger_causality.py           # Visualisierung von Regressions- und GC-Ergebnissen
â”‚   â”‚   â”œâ”€â”€ prepare_PPT.py                      # Automatisierte Erstellung von PowerPoint-Slides fÃ¼r ErgebnisprÃ¤sentationen
â”‚   â”‚   â”œâ”€â”€ read_articles.py                    # Artikel-Visualisierung / Content-Inspection
â”‚   â”‚   â””â”€â”€ stationarity_report.py              # Automatisierter Report zu ADF-, PP- und KPSS-Tests
â”‚   â”‚
â”‚   â”œâ”€â”€ databases/
â”‚   â”‚   â””â”€â”€ create_database.py                  # Datenbank-Schema-Definition (SQLite-Setup & Table-Creation)
â”‚   â”‚
â”‚
â”œâ”€â”€ scripts/                                    # CLI-Wrappers fÃ¼r reproduzierbare Pipelines (Command-Line Interface)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ estimate_collider_granger_causality.py  # Erweiterter GC-Test mit Collider-Kontrolle
â”‚   â”œâ”€â”€ init_jvm.py                             # Initialisierung von Java-Umgebungen fÃ¼r IDTxl (TE)
â”‚   â”œâ”€â”€ run_clean_database.py                   # FÃ¼hrt Bereinigungs-Pipeline aus
â”‚   â”œâ”€â”€ run_combine_article_dbs.py              # Kombiniert Artikel-Datenbanken
â”‚   â”œâ”€â”€ run_construct_AINI_variables.py         # Baut finale AINI-Features & Zeitreihen
â”‚   â”œâ”€â”€ run_create_database.py                  # Erstellt DB-Schema & Tabellen
â”‚   â”œâ”€â”€ run_estimate_granger_causality.py       # Startet Granger-Causality-Analyse
â”‚   â”œâ”€â”€ run_estimate_ols.py                     # FÃ¼hrt OLS-Regressionen aus
â”‚   â”œâ”€â”€ run_fix_article_ids.py                  # Repariert doppelte IDs in Datenbanken
â”‚   â”œâ”€â”€ run_load_financial_data.py              # LÃ¤dt & speichert Finanzzeitreihen (Batch-Mode)
â”‚   â”œâ”€â”€ run_naive_labeling.py                   # Heuristische Labeling-Baseline (Rule-based)
â”‚   â”œâ”€â”€ run_predict_AINI_FinBERT_prelabeled_fin.py  # Finetuned FinBERT-Inference auf vorannotierten Daten
â”‚   â”œâ”€â”€ run_predict_AINI_FinBERT_window.py      # Batch-Inference der window-basierten AINI-Modelle
â”‚   â”œâ”€â”€ run_predict_binary_AINI_FinBERT.py      # Klassifikations-Pipeline AI/Non-AI
â”‚   â”œâ”€â”€ run_predict_investor_sentiment.py       # Sentiment-Inference fÃ¼r Investorenstimmung
â”‚   â”œâ”€â”€ run_reduce_db_for_sentiment.py          # Reduziert Datenbank auf Sentiment-Relevantes Subset
â”‚   â”œâ”€â”€ run_stationarity_testing.py             # FÃ¼hrt ADF/PP/KPSS-Tests automatisiert aus
â”‚   â”œâ”€â”€ run_wsj_crawler.py                      # Crawlt WSJ-Archivseiten
â”‚   â””â”€â”€ run_wsj_scraper.py                      # Extrahiert Artikelinhalte (nach Crawl)
â”‚ 
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ analyse_gc_results.ipynb               # Analyse & Visualisierung der Granger-Causality-Resultate
â”‚   â”œâ”€â”€ benchmark_windows.ipynb                # Vergleich unterschiedlicher Kontext-Fensterstrategien
â”‚   â”œâ”€â”€ calc_CAPM.ipynb                        # DurchfÃ¼hrung von CAPM-Regressionen (Asset Pricing)
â”‚   â”œâ”€â”€ compare_annotations.ipynb              # Evaluation der Label-Konsistenz zwischen Annotatoren
â”‚   â”œâ”€â”€ compare_class_variants.ipynb           # Vergleich verschiedener Modell-Konfigurationen 
â”‚   â”œâ”€â”€ exploratory_analysis_aini.ipynb        # Explorative Analyse der AINI-Zeitreihen
â”‚   â”œâ”€â”€ exploratory_custom_fin.ipynb           # Analyse der Fine-Tuning-Resultate von FinBERT
â”‚   â”œâ”€â”€ exploratory_analysis_raw_res.ipynb     # Analyse der Roh-Annotationsergebnisse
â”‚   â”œâ”€â”€ exploratory_analysis_wsj.ipynb         # Datenexploration: WSJ-Korpus
â”‚   â”œâ”€â”€ label_manually.ipynb                   # Manuelle Annotation von Artikeln (Human-in-the-Loop)
â”‚   â”œâ”€â”€ sample_articles.ipynb                  # Sampling & Randomisierung fÃ¼r Annotationen
â”‚   â”œâ”€â”€ stationarity_evaluation.ipynb          # Diagnostik zu StationaritÃ¤t & Lag-Strukturen
â”‚   â”œâ”€â”€ subset_for_latex.ipynb                 # Aufbereitung fÃ¼r LaTeX-Reporting (Legacy)
â”‚   â”œâ”€â”€ train_FinBERT_annot.ipynb              # Fine-Tuning-Pipeline fÃ¼r FinBERT
â”‚   â””â”€â”€ visualize_aini_variables.ipynb         # Explorative Visualisierung der AINI-Features (Legacy)
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                                   # Rohdaten (Artikel, Kurszeitreihen, externe Indizes)
â”‚   â”œâ”€â”€ interim/                               # Zwischenschritte (annotierte Samples, Preprocessed Corpora)
â”‚   â””â”€â”€ processed/
â”‚       â”œâ”€â”€ variables/                         # Finalisierte Features & Ergebnis-Variablen (AINI, GC, TE)
â”‚       â””â”€â”€ articles/                          # Bereinigte Artikeldaten (Text-Corpus fÃ¼r Inferenz)
â”‚
â””â”€â”€ models/                                    # Trainierte Modelle & Weights (FinBERT-Checkpoints, Tokenize Configs)

```

# Datenkatalog

Dieser Katalog dokumentiert die im Projekt **AI Narrative Index (AINI)** verwendeten und erzeugten DatensÃ¤tze.  
Die Struktur folgt **MLOps-Best Practices**:
- **Nachvollziehbarkeit (Traceability):** jeder Datensatz ist seinem erzeugenden Skript zugeordnet.
- **Reproduzierbarkeit:** die Pipeline raw â†’ interim â†’ processed ist transparent dokumentiert.
- **Versionierung:** Platzhalter `{year}` bzw. `{vers}` trennen ZeitrÃ¤ume/Versionen sauber.
- **Auditierbarkeit:** die Herkunft sÃ¤mtlicher Transformationen ist festgehalten.

---

## ğŸ“‚ `data/raw/`

Rohdaten, nach Erhebung unverÃ¤nderlich.  
Single Source of Truth fÃ¼r alle nachgelagerten Schritte.

### ğŸ“‚ `articles/`

| Datei | Beschreibung | Herkunft |
|------|--------------|----------|
| `articlesWSJ_{year}.db` | WSJ-Rohdatenbanken mit `articles` und `articles_index` | Erstellt via `create_database.py`, befÃ¼llt durch `wsj_archive_scraper.py` & `wsj_archive_crawler.py` |

### ğŸ“‚ `financial/`

Alle Dateien enthalten OHLCV-Daten: `Date`, `Ticker`, `Open`, `High`, `Low`, `Close`, `Adj Close`, `Volume`.  
Erzeugt mit `load_financial_data.py`.

| Datei | Beschreibung |
|------|--------------|
| `{TICKER}_full_2023_2025.csv` | TÃ¤gliche OHLCV fÃ¼r Einzelticker (z. B. `AAPL`, `NVDA`, `MSFT`) |
| `full_daily_2023_2025.csv` | Aggregierte OHLCV-Daten fÃ¼r alle Ticker |

---

## ğŸ“‚ `data/interim/`

Ablage fÃ¼r Experimente, Human-in-the-Loop-Aufgaben und teilweise verarbeitete Daten.  
Genutzt fÃ¼r **Annotation, Sampling und Benchmarks**.

### Sampling & Annotation

| Datei | Beschreibung | Herkunft |
|------|--------------|----------|
| `articles_WSJ_batch_{1â€“4}.csv` | Zufallsstichproben fÃ¼r Annotation | `sample_articles.ipynb` |
| `articles_WSJ_sub500.csv` | Initiales 500-Artikel-Subset (Basis fÃ¼r Batches) | `sample_articles.ipynb` |
| `articles_WSJ_batch_{n}_annotator.csv` | Labels der professionellen Annotatorin / des Annotators | Extern â†’ Import |
| `articles_WSJ_batch_{n}_author.csv` | Autor*innen-Labels | `label_manually.ipynb` |
| `*_subsample_author.csv` | 25 % Autor*innen-Subsample | Manuelle Auswahl |

---

## ğŸ“‚ `data/processed/`

Kanonische DatensÃ¤tze fÃ¼r **Training, Evaluation und Auswertung**.  
ZwischenstÃ¤nde (Rauschen, Uneinigkeit) sind bereinigt.

### ğŸ“‚ `articles/`

| Datei | Beschreibung | Herkunft |
|------|--------------|----------|
| `articlesWSJ_clean_{year}.db` | Bereinigte WSJ-Artikel (StÃ¶rmuster entfernt) | `clean_database.py` (Muster aus `corpus_cleaning.py`) |
| `annotated_subsample_WSJ_final.csv` | Konsensus-Labels nach KonfliktlÃ¶sung | `compare_annotations.ipynb` |
| `articles_WSJ_batch_{n}_final.csv` | Final abgestimmte Batch-Labels | `compare_annotations.ipynb` |

---

## ğŸ“‚ `variables/`

Modellausgaben, Diagnostik und statistische Ergebnisse.  
Alle **Ergebnisse sind aus dem Code reproduzierbar**.

| Datei | Beschreibung | Herkunft |
|------|--------------|----------|
| `w0_AINI_variables.csv`, `w1_AINI_variables.csv`, `w2_AINI_variables.csv`, `binary_AINI_variables.csv` | AINI-Variablen (normalisiert + EMA Î±=0.2/0.8) | `construct_AINI_variables.py` |
| `FinBERT_AINI_prediction_{year}_windowsize_{n}.csv` | Kontextfenster-Vorhersagen (âˆ’1, 0, 1) | `predict_AINI_FinBERT_window.py` |
| `FinBERT_binary_prediction_{year}.csv` | BinÃ¤re FinBERT-Vorhersagen auf vorlabelten Daten | `predict_AINI_FinBERT_prelabeled_fin.py` |
| `granger_causality_{spec}.csv` | GC-Ergebnisse (AINI â†” Renditen) mit 10k Bootstrap + FDR | `estimate_granger_causality.py` |
| `ols_sameday_mbboot_fdr_{spec}.csv` | Zeitgleiche OLS-Effekte | `estimate_OLS.py` |
| `diagnostics_{spec}.csv` | OLS-Residualdiagnostik (Ljung-Box, BG, ARCH-LM, â€¦) | `ols_residual_diagnostics.py` |
| `combined_te_results_window_1.csv` | Transfer-Entropy-Ergebnisse | `calc_entropy.py` |
| `extrema.csv` | Minima/Maxima der AINI-Variablen | `exploratory_analysis_aini.ipynb` |
| `{vers}_AINI_variables.csv` | AINI-MaÃŸe (normalisiert + EMA, relativ) | `run_construct_AINI_variables.py` |
| `extrema.csv` | Min/Max nach MaÃŸanzahl | `exploratory_analysis_results.ipynb` |
| `naive_AI_labels_{year}.csv` | WÃ¶rterbuchbasierte AI-Relevanz-Labels | `label_articles.py` (`naive_labeling`) |
| `n_articles.csv` | Artikelanzahl pro Tag | `exploratory_analysis_aini.ipynb` |

---

### Hinweis

Die gescrapten Inhalte werden ausschlieÃŸlich zu akademischen Forschungszwecken verwendet und aus urheberrechtlichen GrÃ¼nden **nicht** Ã¶ffentlich geteilt.  
Die trainierten Modelle kÃ¶nnen auf Anfrage geteilt werden (abhÃ¤ngig von GrÃ¶ÃŸe und Nutzungskontext).

---

## Autor & Kontext

Dieses Repository bildet die empirische Grundlage einer Masterarbeit in Volkswirtschaftslehre und verbindet:

- **Behavioral Finance & Effizienzmarkthypothese**
- **NLP und Deep Learning (Transformer)**
- **Ã–konometrische Inferenz**

---

## Kontakt

- ğŸ“§ `lars.augustat@icloud.com`  
- ğŸŒ [LinkedIn-Profil](https://www.linkedin.com/in/lars-augustat/)
