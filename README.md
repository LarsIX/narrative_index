# AI Narrative Index (AINI)

Dieses Repository dokumentiert die vollstÃ¤ndige Forschungspipeline zur Konstruktion des **AI Narrative Index (AINI)** â€” einer Zeitreihe, die misst, wie KÃ¼nstliche Intelligenz (KI) in Finanznachrichten dargestellt wird.  

Die Indexwerte basieren auf Artikeln des **Wall Street Journal (WSJ)** (Zeitraum 2023â€“2025) und werden als erklÃ¤rende Variablen zur Prognose von Aktienrenditen eingesetzt.  

Das Projekt integriert **Transformer-basierte NLP-Methoden**, **manuelle Annotation**, **Deep-Learning-Finetuning** sowie **statistische Inferenz** â€” und folgt dabei einer modularen, reproduzierbaren Architektur.  

Das folgende Flussdiagramm veranschaulicht den gesamten Prozess.*

![Flowchart](https://github.com/user-attachments/assets/1296faff-9172-4a18-af42-16b829f4c823)

*Der Prozessablauf ist in englischer Sprache wiedergegeben, da die gesamte Arbeit in Englisch verfasst wird.

---

## Forschungsziele

- **Entwicklung mehrerer Varianten des AI Narrative Index (AINI)** mittels Transformer-Modellen  
- **Quantifizierung narrativer Hype-Effekte** auf Marktdynamiken anhand von Granger-KausalitÃ¤t  
- **Sicherung wissenschaftlicher ValiditÃ¤t** durch Annotation mit Doppel-Codierung, diagnostische Tests und resampling-basierter Inferenz  

---

## Konstruktion des AINI

Die Messung erfolgt durch die Kombination von **menschlicher Annotation, Transformer-Modellen und lexikonbasierten Methoden**.

### 1. Manuelle Annotation & Finetuning von FinBERT

- Erstellung eines manuell annotierten Datensatzes mit **unabhÃ¤ngiger Doppelannotation** und anschlieÃŸender Verifikation (double-blind).
- Annotation nach **AI-Relevanz** (binÃ¤re Klassifikation)  

- Finetuning eines **FinBERT-Modells** unter Verwendung von:  
  - Einsatz einer klassenÂ­gewichteten Verlustfunktion zum **Ausgleich von Klassenungleichgewichten**.  
  - Extraktion rund um **Kontextfenster**  
  - **Early Stopping** und detailliertem Evaluations-Logging  

- Das Modell identifiziert KI-bezogene Narrative in WSJ-Artikeln.  
- Im Anschluss wird eine **Sentimentanalyse** (mit [ProsusAI/finbert](https://huggingface.co/ProsusAI/finbert)) durchgefÃ¼hrt.  
- Die resultierenden Sentimentausgaben werden **weiterverarbeitet** (Normalisierung, Aggregation, exponentielle GlÃ¤ttung) und zu einer **tÃ¤glichen AINI-Zeitreihe** verdichtet.  

---

### 2. Lexikon-gestÃ¼tzte Snippet-Reduktion

- **Identifikation** KI-relevanter Artikel durch **SchlÃ¼sselwortlisten**.  
- Anwendung von **FinBERT** auf extrahierte **Textausschnitte** rund um verschiedene **Kontextfenster**.  
- Die resultierenden Sentimentausgaben werden ebenfalls **normalisiert, aggregiert und geglÃ¤ttet** und in **tÃ¤gliche AINI-Zeitreihen** Ã¼berfÃ¼hrt.  

---

## Statistische Inferenz

Zur Analyse der Wechselwirkungen zwischen Narrativen und FinanzmÃ¤rkten werden **Ã¶konometrische Verfahren** eingesetzt.

### StationaritÃ¤tstests
- Augmented Dickey-Fuller (ADF)  
- Phillips-Perron (PP)  
- KPSS  

Alle Variablen werden vor der Modellierung auf StationaritÃ¤t geprÃ¼ft.  

### Granger-KausalitÃ¤t (GC)

Die Granger KausalitÃ¤t zwischen AINI und Finanzvariablen wird getestet mittels:

- **Wild Residual Bootstrap** (10.000 Resamples, Rademacher-Gewichte) â†’ robuste empirische p-Werte  
- **Benjaminiâ€“Hochberg-Korrektur** zur Kontrolle der Fehlerquote bei multiplen Tests  

Regressionsspezifikation (mit VIX-Wachstumsrate als Kontrollvariable fÃ¼r Marktrisiko*):

![GC Formel VIX](<GC VIX-1.png>)  
![Legende](<GC Legend-1-1.png>)

*Weitere Kontrollvariablen: Anzahl der tÃ¤glichen Artikel, Marktindex (S&P 500) & Index fÃ¼r Halbleiter (SOX).

---

## Ergebnisse (Auswahl)

- FÃ¼r stark KI-exponierte Unternehmen (z. B. NVIDIA, Broadcom) zeigen sich **robuste ZusammenhÃ¤nge** AINI â†’ Renditen.  
- Die Signifikanz ist sowohl nach **analytischen Verfahren (HC3)** als auch nach **Bootstrap-Inferenz mit FDR-Korrektur** nachweisbar.  

![Scatter of coefficients](image.png)  

---

# Projektstruktur

Die Implementierung folgt einem **modularen Aufbau nach Best Practices**.  
Alle Komponenten sind klar getrennt (Datenakquise, Vorverarbeitung, Annotation, Modellierung, Visualisierung), sodass die Pipeline reproduzierbar ausgefÃ¼hrt werden kann.

```text
AI_narrative_index/
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ fetch_data/
â”‚   â”‚   â”œâ”€â”€ load_financial_data.py              # Download von Finanzmarktdaten
â”‚   â”‚   â”œâ”€â”€ wsj_archive_crawler.py              # Crawlt WSJ-Archivseiten, sammelt Artikel-URLs
â”‚   â”‚   â””â”€â”€ wsj_archive_scraper.py              # LÃ¤dt vollstÃ¤ndige Artikelinhalte von den URLs
â”‚   â”‚
â”‚   â”œâ”€â”€ preprocessing/
â”‚   â”‚   â”œâ”€â”€ clean_database.py                   # Filtert Artikel nach Sektionen, LÃ¤nge, Duplikaten
â”‚   â”‚   â”œâ”€â”€ corpus_cleaning.py                  # Entfernt UI-/Meta-Elemente aus Artikeltexten
â”‚   â”‚   â”œâ”€â”€ reduce_db_for_sentiment.py          # Extrahiert Subset fÃ¼r Sentimentanalyse
â”‚   â”‚   â”œâ”€â”€ combine_article_dbs.py              # VerknÃ¼pft Jahresdatenbanken zu einer CSV
â”‚   â”‚   â”œâ”€â”€ section_filtering.py                # Entfernt irrelevante WSJ-Sektionen
â”‚   â”‚   â””â”€â”€ simple_ai_filter.py                 # Markiert Artikel mit KI-SchlÃ¼sselwÃ¶rtern
â”‚   â”‚
â”‚   â”œâ”€â”€ annotation/
â”‚   â”‚   â”œâ”€â”€ comparing_annotations.py            # LÃ¶st Konflikte zwischen Annotatoren
â”‚   â”‚   â””â”€â”€ label_articles.py                   # Interaktives Tool fÃ¼r Annotation von AI/Hype
â”‚   â”‚  
â”‚   â”‚
â”‚   â”œâ”€â”€ modelling/
â”‚   â”‚   â”œâ”€â”€ ai_windows.py                       # Kontextuelle Snippets um KI-Begriffe extrahieren
â”‚   â”‚   â”œâ”€â”€ calculate_summary_statistics.py     # Berechnet deskriptive Statistiken zu AINI
â”‚   â”‚   â”œâ”€â”€ compute_extrema.py                  # Extremwerte (Min/Max) der AINI-Varianten
â”‚   â”‚   â”œâ”€â”€ construct_AINI_variables.py         # Baut AINI-Zeitreihe (Normierung, EMAs)
â”‚   â”‚   â”œâ”€â”€ CustomFinBERT.py                    # Custom-FinBERT mit Dropout & Class Weights
â”‚   â”‚   â”œâ”€â”€ stationarity_testing.py             # StationaritÃ¤tstests (ADF, PP)
â”‚   â”‚   â”œâ”€â”€ estimate_granger_causality.py       # Granger-KausalitÃ¤t mit Bootstrap-Verfahren
â”‚   â”‚   â”œâ”€â”€ predict_binary_AINI_FinBERT.py      # Klassifikation AI vs. Non-AI via Custom-FinBERT
â”‚   â”‚   â””â”€â”€ predict_AINI_FinBERT_window.py      # Kontextbasierte inferenz von Sentiments
â”‚   â”‚
â”‚   â”œâ”€â”€ visualizations/
â”‚   â”‚   â”œâ”€â”€ construct_latex_tables.py           # Automatisierte LaTeX-Tabellen fÃ¼r Thesis
â”‚   â”‚   â””â”€â”€ plot_granger_causality.py           # Visualisierung der GC-Ergebnisse
â”‚   â”‚
â”‚   â”œâ”€â”€ databases/
â”‚   â”‚   â”œâ”€â”€ fix_article_ids_in_db.py            # Stellt eindeutige article_id sicher
â”‚   â”‚   â””â”€â”€ create_database.py                  # Erstellt SQL-Datenbankstruktur
â”‚   â”‚
â”‚   â”œâ”€â”€ scripts/                                # CLI-Wrapper fÃ¼r reproduzierbare AusfÃ¼hrung
â”‚   â”‚   â”œâ”€â”€ run_create_database.py              # Initialisiert Datenbankschema
â”‚   â”‚   â”œâ”€â”€ run_wsj_scraper.py                  # Startet Crawler + Scraper
â”‚   â”‚   â”œâ”€â”€ run_clean_database.py               # Bereinigt Artikeldatenbank
â”‚   â”‚   â”œâ”€â”€ run_reduce_db_for_sentiment.py      # Reduziert DB fÃ¼r Sentiment-Analysen
â”‚   â”‚   â”œâ”€â”€ run_predict_investor_sentiment.py   # Sentiment-Prediction mit Standard-FinBERT
â”‚   â”‚   â”œâ”€â”€ run_predict_binary_AINI_FinBERT.py  # Binary-Klassifikation AI-Narrative
â”‚   â”‚   â”œâ”€â”€ run_predict_AINI_FinBERT_window.py  # Klassifikation mit Kontextfenstern
â”‚   â”‚   â”‚â”€â”€ run_combine_article_dbs.py          # VerknÃ¼pft WSJ-Datenbanken (mehrere Jahre)
â”‚   â”‚   â”‚â”€â”€ run_fix_article_ids.py              # Stellt eindeutige IDs sicher
â”‚   â”‚   â”‚â”€â”€ run_estimate_granger_causality.py   # SchÃ¤tzt Granger-KausalitÃ¤t
â”‚   â”‚   â”‚â”€â”€ run_estimate_OLS.py                 # OLS-SchÃ¤tzung (Kontemporane Effekte)
â”‚   â”‚   â”‚â”€â”€ run_naive_labeling.py               # Naive KI-Labels via Keywords
â”‚   â”‚   â””â”€â”€ run_construct_AINI_variables.py     # Baut finale AINI-Variablen
â”‚
â”œâ”€â”€ notebooks/
â”‚       â”œâ”€â”€ analyse_gc_results.ipynb           # Analyse von Regressionsergebnissen
â”‚       â”œâ”€â”€ benchmark_windows.ipynb            # Vergleicht Kontextfenster
â”‚       â”œâ”€â”€ compare_annotations.ipynb          # KonfliktlÃ¶sung Annotationen
â”‚       â”œâ”€â”€ compare_class_variants.ipnyb       # Vergleicht Klassifikationsschemata 
â”‚       â”œâ”€â”€ exploratory_analysis_aini.ipynb    # Analyse AINI-Varianten
â”‚       â”œâ”€â”€ exploratory_analysis_labels.ipynb  # Analyse AI-Labels v. custom FinBERT
â”‚       â”œâ”€â”€ exploratory_analysis_raw_res.ipynb # Analyse unverarbeitete Sentimentzeitreihen
â”‚       â”œâ”€â”€ exploratory_analysis_wsj.ipynb     # Analyse WSJ-Korpus 
â”‚       â”œâ”€â”€ label_manually.ipynb               # Annotation durch den Author
â”‚       â”œâ”€â”€ sameple_articles.ipynb             # Erstellung von Samples zur Annotation
â”‚       â”œâ”€â”€ subset_for_latex.ipynb             # Konstruktion von Regressionstabellen Thesis
â”‚       â”œâ”€â”€ subset_VIX.ipynb                   # Aufbereitung VIX-Zeitreihen
â”‚       â”œâ”€â”€ train_FinBERT_annot.ipynb          # Fine-Tuning von FinBERT
â”‚       â””â”€â”€ visualize_aini_variables.ipynb     # AINI-Trends visualisieren
â”‚       
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                                   # Rohdaten (Artikel, Finanzmarkt)
â”‚   â”œâ”€â”€ interim/                               # Zwischendaten (Annotation, Subsets)
â”‚   â””â”€â”€ processed/
â”‚       â”œâ”€â”€ variables/                         # Finale Variablen (AINI, GC, TE etc.)
â”‚       â””â”€â”€ articles/                          # Bereinigte Artikeltexte
â”‚
â””â”€â”€ models/                                    # Fine-Tuned FinBERT & Sentiment-Modelle

```

# Datenkatalog

Dieser Katalog dokumentiert die im Projekt **AI Narrative Index (AINI)** verwendeten und erzeugten DatensÃ¤tze.  
Die Struktur folgt **MLOps-Best Practices**:
- **Nachvollziehbarkeit (Traceability):** jeder Datensatz ist seinem erzeugenden Skript zugeordnet.
- **Reproduzierbarkeit:** die Pipeline raw â†’ interim â†’ processed ist transparent dokumentiert.
- **Versionierung:** Platzhalter `{year}` bzw. `{vers}` trennen ZeitrÃ¤ume/Versionen sauber.
- **Auditierbarkeit:** die Herkunft sÃ¤mtlicher Transformationen ist festgehalten.

---

## ğŸ“‚ `data/raw/`

Rohdaten, nach Erhebung unverÃ¤nderlich.  
Single Source of Truth fÃ¼r alle nachgelagerten Schritte.

### ğŸ“‚ `articles/`

| Datei | Beschreibung | Herkunft |
|------|--------------|----------|
| `articlesWSJ_{year}.db` | WSJ-Rohdatenbanken mit `articles` und `articles_index` | Erstellt via `create_database.py`, befÃ¼llt durch `wsj_archive_scraper.py` & `wsj_archive_crawler.py` |

### ğŸ“‚ `financial/`

Alle Dateien enthalten OHLCV-Daten: `Date`, `Ticker`, `Open`, `High`, `Low`, `Close`, `Adj Close`, `Volume`.  
Erzeugt mit `load_financial_data.py`.

| Datei | Beschreibung |
|------|--------------|
| `{TICKER}_full_2023_2025.csv` | TÃ¤gliche OHLCV fÃ¼r Einzelticker (z. B. `AAPL`, `NVDA`, `MSFT`) |
| `full_daily_2023_2025.csv` | Aggregierte OHLCV-Daten fÃ¼r alle Ticker |

---

## ğŸ“‚ `data/interim/`

Ablage fÃ¼r Experimente, Human-in-the-Loop-Aufgaben und teilweise verarbeitete Daten.  
Genutzt fÃ¼r **Annotation, Sampling und Benchmarks**.

### Sampling & Annotation

| Datei | Beschreibung | Herkunft |
|------|--------------|----------|
| `articles_WSJ_batch_{1â€“4}.csv` | Zufallsstichproben fÃ¼r Annotation | `sample_articles.ipynb` |
| `articles_WSJ_sub500.csv` | Initiales 500-Artikel-Subset (Basis fÃ¼r Batches) | `sample_articles.ipynb` |
| `articles_WSJ_batch_{n}_annotator.csv` | Labels der professionellen Annotatorin / des Annotators | Extern â†’ Import |
| `articles_WSJ_batch_{n}_author.csv` | Autor*innen-Labels | `label_manually.ipynb` |
| `*_subsample_author.csv` | 25 % Autor*innen-Subsample | Manuelle Auswahl |

---

## ğŸ“‚ `data/processed/`

Kanonische DatensÃ¤tze fÃ¼r **Training, Evaluation und Auswertung**.  
ZwischenstÃ¤nde (Rauschen, Uneinigkeit) sind bereinigt.

### ğŸ“‚ `articles/`

| Datei | Beschreibung | Herkunft |
|------|--------------|----------|
| `articlesWSJ_clean_{year}.db` | Bereinigte WSJ-Artikel (StÃ¶rmuster entfernt) | `clean_database.py` (Muster aus `corpus_cleaning.py`) |
| `annotated_subsample_WSJ_final.csv` | Konsensus-Labels nach KonfliktlÃ¶sung | `compare_annotations.ipynb` |
| `articles_WSJ_batch_{n}_final.csv` | Final abgestimmte Batch-Labels | `compare_annotations.ipynb` |

---

## ğŸ“‚ `variables/`

Modellausgaben, Diagnostik und statistische Ergebnisse.  
Alle **Ergebnisse sind aus dem Code reproduzierbar**.

| Datei | Beschreibung | Herkunft |
|------|--------------|----------|
| `w0_AINI_variables.csv`, `w1_AINI_variables.csv`, `w2_AINI_variables.csv`, `binary_AINI_variables.csv` | AINI-Variablen (normalisiert + EMA Î±=0.2/0.8) | `construct_AINI_variables.py` |
| `FinBERT_AINI_prediction_{year}_windowsize_{n}.csv` | Kontextfenster-Vorhersagen (âˆ’1, 0, 1) | `predict_AINI_FinBERT_window.py` |
| `FinBERT_binary_prediction_{year}.csv` | BinÃ¤re FinBERT-Vorhersagen auf vorlabelten Daten | `predict_AINI_FinBERT_prelabeled_fin.py` |
| `granger_causality_{spec}.csv` | GC-Ergebnisse (AINI â†” Renditen) mit 10k Bootstrap + FDR | `estimate_granger_causality.py` |
| `ols_sameday_mbboot_fdr_{spec}.csv` | Zeitgleiche OLS-Effekte | `estimate_OLS.py` |
| `diagnostics_{spec}.csv` | OLS-Residualdiagnostik (Ljung-Box, BG, ARCH-LM, â€¦) | `ols_residual_diagnostics.py` |
| `combined_te_results_window_1.csv` | Transfer-Entropy-Ergebnisse | `calc_entropy.py` |
| `extrema.csv` | Minima/Maxima der AINI-Variablen | `exploratory_analysis_aini.ipynb` |
| `{vers}_AINI_variables.csv` | AINI-MaÃŸe (normalisiert + EMA, relativ) | `run_construct_AINI_variables.py` |
| `extrema.csv` | Min/Max nach MaÃŸanzahl | `exploratory_analysis_results.ipynb` |
| `naive_AI_labels_{year}.csv` | WÃ¶rterbuchbasierte AI-Relevanz-Labels | `label_articles.py` (`naive_labeling`) |
| `n_articles.csv` | Artikelanzahl pro Tag | `exploratory_analysis_aini.ipynb` |

---

### Hinweis

Die gescrapten Inhalte werden ausschlieÃŸlich zu akademischen Forschungszwecken verwendet und aus urheberrechtlichen GrÃ¼nden **nicht** Ã¶ffentlich geteilt.  
Die trainierten Modelle kÃ¶nnen auf Anfrage geteilt werden (abhÃ¤ngig von GrÃ¶ÃŸe und Nutzungskontext).

---

## Autor & Kontext

Dieses Repository bildet die empirische Grundlage einer Masterarbeit in Volkswirtschaftslehre und verbindet:

- **Behavioral Finance & Effizienzmarkthypothese**
- **NLP und Deep Learning (Transformer)**
- **Ã–konometrische Inferenz**

---

## Kontakt

- ğŸ“§ `lars.augustat@icloud.com`  
- ğŸŒ [LinkedIn-Profil](https://www.linkedin.com/in/lars-augustat/)
