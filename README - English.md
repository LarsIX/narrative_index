# AI Narrative Index (AINI)

This repository documents the complete research pipeline for constructing the **AI Narrative Index (AINI)** â€” a time series measuring how Artificial Intelligence (AI) is represented in financial news.  

The index values are based on articles from the **Wall Street Journal (WSJ)** (2023â€“2025) and are used as explanatory variables for predicting stock returns.  

The project integrates **Transformer-based NLP methods**, **manual annotation**, **deep learning fine-tuning**, and **statistical inference** â€” following a modular and reproducible architecture.  

The flowchart below illustrates the entire process.*  

![Flowchart](https://github.com/user-attachments/assets/1296faff-9172-4a18-af42-16b829f4c823)

*The process is shown in English since the entire thesis is written in English.

---

## Research Objectives

- **Development of multiple variants of the AI Narrative Index (AINI)** using Transformer models  
- **Quantification of narrative hype effects** on market dynamics via Granger causality  
- **Ensuring scientific validity** through double-coding annotation, diagnostic tests, and resampling-based inference  

---

## Construction of the AINI

The measurement combines **human annotation, Transformer models, and lexicon-based methods**.

### 1. Manual Annotation & FinBERT Fine-Tuning

- Creation of a manually annotated dataset with **independent double annotation** and subsequent verification (double-blind).  
- Annotation of **AI relevance** (binary classification).  

- Fine-tuning of a **FinBERT model** using:  
  - A class-weighted loss function to **address class imbalance**  
  - Extraction around **context windows**  
  - **Early stopping** and detailed evaluation logging  

- The model identifies AI-related narratives in WSJ articles.  
- A subsequent **sentiment analysis** (with [ProsusAI/finbert](https://huggingface.co/ProsusAI/finbert)) is conducted.  
- The resulting sentiment outputs are **further processed** (normalization, aggregation, exponential smoothing) and condensed into a **daily AINI time series**.  

---

### 2. Lexicon-Based Snippet Reduction

- **Identification** of AI-related articles via **keyword lists**  
- Application of **FinBERT** on extracted **text snippets** around various **context windows**  
- Sentiment outputs are likewise **normalized, aggregated, and smoothed**, then transformed into **daily AINI time series**  

---

## Statistical Inference

To analyze the interactions between narratives and financial markets, **econometric methods** are applied.

### Stationarity Tests
- Augmented Dickey-Fuller (ADF)  
- Phillips-Perron (PP)  
- KPSS  

All variables are tested for stationarity prior to modeling.  

### Granger Causality (GC)

Granger causality between AINI and financial variables is tested using:

- **Wild Residual Bootstrap** (10,000 resamples, Rademacher weights) â†’ robust empirical p-values  
- **Benjaminiâ€“Hochberg correction** for controlling false discovery rate in multiple tests  

Regression specification (with VIX growth rate as a control for market risk*):  

![GC Formula VIX](<GC VIX-1.png>)  
![Legend](legende_klein-1.png)

*Additional control variables: number of daily articles, market index (S&P 500), and semiconductor index (SOX).  

---

## Selected Results

The first chart illustrates the AI Narrative Index (AINI) in different variants, where **prefixes indicate the size** of the applied **context window**.  
**Variant C** is based on the **full article** (title + main text) and uses the maximum possible input of 512 tokens.  
The displayed **series** represent the **mean of all variables** (see formula) within each context window.  

![AINI](aini_means.png)

The next chart shows the estimated regression coefficients of the different AINI variables for the respective stocks & ETFs.  
Significance is independently confirmed by both methods â€” analytic tests as well as bootstrap inference with FDR correction.  

![Scatter of coefficients](image.png)  

**Preliminary conclusions:**  
- Context window size correlates with the negativity of the AINI.  
- For w=0, 1 & 2, the indices peak at partly predictable points in time.  
- For highly AI-exposed companies (e.g., NVIDIA, Broadcom), **robust relationships** AINI â†’ returns can be observed.  

---

## Project Structure

The implementation follows a **modular best-practice design**.  
All components are clearly separated (data acquisition, preprocessing, annotation, modeling, visualization), ensuring the pipeline can be executed reproducibly.  

```text
AI_narrative_index/
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ fetch_data/
â”‚   â”‚   â”œâ”€â”€ load_financial_data.py              # Download financial market data
â”‚   â”‚   â”œâ”€â”€ wsj_archive_crawler.py              # Crawl WSJ archive pages, collect URLs
â”‚   â”‚   â””â”€â”€ wsj_archive_scraper.py              # Download full article contents
â”‚   â”‚
â”‚   â”œâ”€â”€ preprocessing/
â”‚   â”‚   â”œâ”€â”€ clean_database.py                   # Filter articles by section, length, duplicates
â”‚   â”‚   â”œâ”€â”€ corpus_cleaning.py                  # Remove UI/meta elements from text
â”‚   â”‚   â”œâ”€â”€ reduce_db_for_sentiment.py          # Extract subset for sentiment analysis
â”‚   â”‚   â”œâ”€â”€ combine_article_dbs.py              # Merge yearly DBs into one CSV
â”‚   â”‚   â”œâ”€â”€ section_filtering.py                # Remove irrelevant WSJ sections
â”‚   â”‚   â””â”€â”€ simple_ai_filter.py                 # Mark articles with AI keywords
â”‚   â”‚
â”‚   â”œâ”€â”€ annotation/
â”‚   â”‚   â”œâ”€â”€ comparing_annotations.py            # Resolve annotator conflicts
â”‚   â”‚   â””â”€â”€ label_articles.py                   # Interactive annotation tool (AI/Hype)
â”‚   â”‚
â”‚   â”œâ”€â”€ modelling/
â”‚   â”‚   â”œâ”€â”€ ai_windows.py                       # Extract contextual snippets around AI terms
â”‚   â”‚   â”œâ”€â”€ calculate_summary_statistics.py     # Descriptive stats for AINI
â”‚   â”‚   â”œâ”€â”€ compute_extrema.py                  # Extremes (Min/Max) of AINI variants
â”‚   â”‚   â”œâ”€â”€ construct_AINI_variables.py         # Build AINI time series (normalization, EMAs)
â”‚   â”‚   â”œâ”€â”€ CustomFinBERT.py                    # Custom FinBERT with dropout & class weights
â”‚   â”‚   â”œâ”€â”€ stationarity_testing.py             # Stationarity tests (ADF, PP)
â”‚   â”‚   â”œâ”€â”€ estimate_granger_causality.py       # Granger causality with bootstrap
â”‚   â”‚   â”œâ”€â”€ predict_binary_AINI_FinBERT.py      # AI vs. Non-AI classification
â”‚   â”‚   â””â”€â”€ predict_AINI_FinBERT_window.py      # Context-based sentiment inference
â”‚   â”‚
â”‚   â”œâ”€â”€ visualizations/
â”‚   â”‚   â”œâ”€â”€ construct_latex_tables.py           # Automated LaTeX tables
â”‚   â”‚   â””â”€â”€ plot_granger_causality.py           # Visualize GC results
â”‚   â”‚
â”‚   â”œâ”€â”€ databases/
â”‚   â”‚   â”œâ”€â”€ fix_article_ids_in_db.py            # Ensure unique article_id
â”‚   â”‚   â””â”€â”€ create_database.py                  # Create SQL DB structure
â”‚   â”‚
â”‚   â”œâ”€â”€ scripts/                                # CLI wrappers for reproducibility
â”‚   â”‚   â”œâ”€â”€ run_create_database.py
â”‚   â”‚   â”œâ”€â”€ run_wsj_scraper.py
â”‚   â”‚   â”œâ”€â”€ run_clean_database.py
â”‚   â”‚   â”œâ”€â”€ run_reduce_db_for_sentiment.py
â”‚   â”‚   â”œâ”€â”€ run_predict_investor_sentiment.py
â”‚   â”‚   â”œâ”€â”€ run_predict_binary_AINI_FinBERT.py
â”‚   â”‚   â”œâ”€â”€ run_predict_AINI_FinBERT_window.py
â”‚   â”‚   â”‚â”€â”€ run_combine_article_dbs.py
â”‚   â”‚   â”‚â”€â”€ run_fix_article_ids.py
â”‚   â”‚   â”‚â”€â”€ run_estimate_granger_causality.py
â”‚   â”‚   â”‚â”€â”€ run_estimate_OLS.py
â”‚   â”‚   â”‚â”€â”€ run_naive_labeling.py
â”‚   â”‚   â””â”€â”€ run_construct_AINI_variables.py
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ analyse_gc_results.ipynb
â”‚   â”œâ”€â”€ benchmark_windows.ipynb
â”‚   â”œâ”€â”€ compare_annotations.ipynb
â”‚   â”œâ”€â”€ compare_class_variants.ipynb
â”‚   â”œâ”€â”€ exploratory_analysis_aini.ipynb
â”‚   â”œâ”€â”€ exploratory_analysis_labels.ipynb
â”‚   â”œâ”€â”€ exploratory_analysis_raw_res.ipynb
â”‚   â”œâ”€â”€ exploratory_analysis_wsj.ipynb
â”‚   â”œâ”€â”€ label_manually.ipynb
â”‚   â”œâ”€â”€ sample_articles.ipynb
â”‚   â”œâ”€â”€ subset_for_latex.ipynb
â”‚   â”œâ”€â”€ subset_VIX.ipynb
â”‚   â”œâ”€â”€ train_FinBERT_annot.ipynb
â”‚   â””â”€â”€ visualize_aini_variables.ipynb
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                                   # Raw data (articles, financials)
â”‚   â”œâ”€â”€ interim/                               # Intermediate data (annotation, subsets)
â”‚   â””â”€â”€ processed/
â”‚       â”œâ”€â”€ variables/                         # Final variables (AINI, GC, TE etc.)
â”‚       â””â”€â”€ articles/                          # Cleaned article texts
â”‚
â””â”€â”€ models/                                    # Fine-tuned FinBERT & sentiment models



# Data Catalog

This catalog documents the datasets used and generated in the **AI Narrative Index (AINI)** project.  
The structure follows **MLOps best practices**:

- **Traceability:** every dataset is linked to its generating script  
- **Reproducibility:** the raw â†’ interim â†’ processed pipeline is fully transparent  
- **Versioning:** placeholders `{year}` / `{vers}` separate time ranges and versions  
- **Auditability:** all transformations are fully documented  

---

## ðŸ“‚ `data/raw/`

Immutable raw data after collection.  
Single source of truth for all downstream steps.  

### ðŸ“‚ `articles/`

| File | Description | Origin |
|------|-------------|--------|
| `articlesWSJ_{year}.db` | WSJ raw databases with `articles` and `articles_index` | Created via `create_database.py`, filled by `wsj_archive_scraper.py` & `wsj_archive_crawler.py` |

### ðŸ“‚ `financial/`

All files contain OHLCV data: `Date`, `Ticker`, `Open`, `High`, `Low`, `Close`, `Adj Close`, `Volume`.  
Generated with `load_financial_data.py`.  

| File | Description |
|------|-------------|
| `{TICKER}_full_2023_2025.csv` | Daily OHLCV for individual tickers (e.g., `AAPL`, `NVDA`, `MSFT`) |
| `full_daily_2023_2025.csv` | Aggregated OHLCV data for all tickers |

---

## ðŸ“‚ `data/interim/`

Storage for experiments, human-in-the-loop tasks, and partially processed data.  
Used for **annotation, sampling, and benchmarks**.  

### Sampling & Annotation

| File | Description | Origin |
|------|-------------|--------|
| `articles_WSJ_batch_{1â€“4}.csv` | Random samples for annotation | `sample_articles.ipynb` |
| `articles_WSJ_sub500.csv` | Initial 500-article subset (basis for batches) | `sample_articles.ipynb` |
| `articles_WSJ_batch_{n}_annotator.csv` | Labels from professional annotator | External â†’ Import |
| `articles_WSJ_batch_{n}_author.csv` | Authorâ€™s labels | `label_manually.ipynb` |
| `*_subsample_author.csv` | 25% author subsample | Manual selection |

---

## ðŸ“‚ `data/processed/`

Canonical datasets for **training, evaluation, and analysis**.  
Noise and disagreements are resolved.  

### ðŸ“‚ `articles/`

| File | Description | Origin |
|------|-------------|--------|
| `articlesWSJ_clean_{year}.db` | Cleaned WSJ articles (noise removed) | `clean_database.py` (patterns from `corpus_cleaning.py`) |
| `annotated_subsample_WSJ_final.csv` | Consensus labels after conflict resolution | `compare_annotations.ipynb` |
| `articles_WSJ_batch_{n}_final.csv` | Final agreed batch labels | `compare_annotations.ipynb` |

---

## ðŸ“‚ `variables/`

Model outputs, diagnostics, and statistical results.  
All **results are reproducible from code**.  

| File | Description | Origin |
|------|-------------|--------|
| `w0_AINI_variables.csv`, `w1_AINI_variables.csv`, `w2_AINI_variables.csv`, `binary_AINI_variables.csv` | AINI variables (normalized + EMA Î±=0.2/0.8) | `construct_AINI_variables.py` |
| `FinBERT_AINI_prediction_{year}_windowsize_{n}.csv` | Context window predictions (âˆ’1, 0, 1) | `predict_AINI_FinBERT_window.py` |
| `FinBERT_binary_prediction_{year}.csv` | Binary FinBERT predictions on pre-labeled data | `predict_AINI_FinBERT_prelabeled_fin.py` |
| `granger_causality_{spec}.csv` | GC results (AINI â†” returns) with 10k bootstrap + FDR | `estimate_granger_causality.py` |
| `ols_sameday_mbboot_fdr_{spec}.csv` | Contemporaneous OLS effects | `estimate_OLS.py` |
| `diagnostics_{spec}.csv` | OLS residual diagnostics (Ljung-Box, BG, ARCH-LM, â€¦) | `ols_residual_diagnostics.py` |
| `combined_te_results_window_1.csv` | Transfer Entropy results | `calc_entropy.py` |
| `extrema.csv` | Min/Max of AINI variables | `exploratory_analysis_aini.ipynb` |
| `{vers}_AINI_variables.csv` | AINI measures (normalized + EMA, relative) | `run_construct_AINI_variables.py` |
| `naive_AI_labels_{year}.csv` | Dictionary-based AI relevance labels | `label_articles.py` (`naive_labeling`) |
| `n_articles.csv` | Number of articles per day | `exploratory_analysis_aini.ipynb` |

---

## Note

The scraped contents are used exclusively for academic research and are **not** shared publicly for copyright reasons.  
The trained models can be shared upon request (depending on size and usage context).  
