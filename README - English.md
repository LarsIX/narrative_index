# AI Narrative Index (AINI)

**Deutsche Version:** [hier](https://github.com/LarsIX/narrative_index/blob/main/README.md)

---

## Overview

This repository documents the complete research and implementation pipeline for constructing the **AI Narrative Index (AINI)** â€” a time series measuring how Artificial Intelligence (AI) is represented in financial news.  
To the authorâ€™s knowledge, this is the **first technology-specific hype index** that quantitatively captures narrative attention and sentiment toward AI.

The project integrates **Transformer-based NLP**, **deep learning**, and **econometric inference** within a **modular and reproducible architecture**.

![Flowchart](https://github.com/user-attachments/assets/1296faff-9172-4a18-af42-16b829f4c823)

*Note: The flowchart is shown in English, as the underlying research and thesis are written in English.*

---

## Research Goals

- Develop multiple **Transformer-based variants** of the AINI (different context windows and FinBERT fine-tuning)
- Quantify **narrative hype effects on financial markets** using Granger causality
- Ensure **scientific validity** through double annotation, diagnostic testing, and resampling-based inference

---

## Construction of the AINI

The index combines **manual annotation**, **fine-tuned language models**, and **lexicon-based methods** to identify and quantify AI-related narratives in financial texts.

### 1. Manual Annotation & Fine-tuning of FinBERT

- Creation of a double-annotated dataset to identify **AI-related articles**  
- Fine-tuning of a **FinBERT model** on this dataset for binary classification (â€œabout AIâ€ / â€œnot about AIâ€)  
- Application of the model to **Wall Street Journal (WSJ)** articles (2023â€“2025)  
- Execution of a **sentiment analysis** using [ProsusAI/finbert](https://huggingface.co/ProsusAI/finbert) on identified narratives  
- Normalization, aggregation, and exponential smoothing of sentiment outputs to produce a **daily time series**

### 2. Lexicon-based Snippet Selection

- Pre-selection of AI-related paragraphs through a **rule-based keyword search**
- Extraction of multiple **context windows** around flagged keywords
- Application of FinBERT to these snippets, followed by **aggregation and smoothing** into daily scores
- Construction of additional AINI variants for robustness analysis

---

## Statistical Inference

The interaction between narratives and financial variables is analyzed using **econometric methods**.

### Stationarity Tests
- Augmented Dickey-Fuller (ADF)  
- Phillips-Perron (PP)  
- KPSS  

All time series were tested for stationarity and differenced when required.

### Granger Causality

To assess directional relationships between AINI and stock returns, Granger causality tests are employed.  
The methodology includes:

- **Wild Residual Bootstrap** (10,000 resamples with Rademacher weights) â†’ robust empirical p-values  
- **Benjaminiâ€“Hochberg correction** to control the false discovery rate across multiple tests  

Example regression specification:

![Granger causality](gc_equ_c.png)

All models were also estimated in the **reverse direction** (log return â†’ AINI) to assess potential feedback effects from market movements to narratives.

*Control variables:* daily growth of article counts, S&P 500 index, SOX index.  
*Lag lengths:* l = Ï âˆˆ {1, 2, 3}

---

## Results (Selected)

### AI Narrative Index (AINI) â€“ Variant Comparison

The variants differ in the size of the applied context window:  
**wâ‚€** uses only the sentence containing an AI keyword (no context integration),  
**wâ‚** extends the window bidirectionally by one sentence before and after the hit,  
**wâ‚‚** covers two surrounding sentences,  
and **custom** processes the entire article (headline + main text, up to 512 tokens).  
Larger context windows capture **greater semantic depth** and **narrative coherence** across text segments.

![AINI](aini_means.png)

### Significant Effects by Asset and Period

The following figure shows significant Granger-causality results (AINI â†’ returns):

![Significant results per asset](vix_aini_to_ret_sig_counts.png)

### Distribution of Regression Coefficients

The distribution of Î³-coefficients illustrates the dispersion and direction of AINI effects:

![Distribution of regressors](distribution_of_gammas.png)

---

## Key Findings

**Model Behavior**
- Larger context windows tend to produce more negative sentiment scores.
- The fine-tuned FinBERT model achieved a weighted Macro-F1 score of **0.92** on the test set.
- The lexicon-based variant performed comparably on the validated dataset.

**Economic Results**
- The AINI series (wâ‚€â€“wâ‚‚) are non-stationary in 2025 â†’ possible regime shift indicator.  
- Consistent with the Efficient Market Hypothesis, most regressions are insignificant.  
- For significant cases, AINI explains only a small share of overall variance but increases short-term return volatility by a factor of 5â€“35.  
- In the reverse direction (returns â†’ AINI), some assets exhibit strong narrative responses (up to 85% explained variation).

**Limitations**
- Based solely on WSJ articles (2023â€“2025)
- Focused on high-growth assets (e.g., NVIDIA)
- Short sample period
- No modeling of non-linear effects

---

## Project Structure

The implementation follows a **modular, MLOps-inspired architecture**.  
All components â€” from data collection to econometric analysis â€” are **separated, reproducible, and accessible via CLI scripts**.

```text
AI_narrative_index/
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ fetch_data/
â”‚   â”‚   â”œâ”€â”€ load_financial_data.py              # Download financial market data
â”‚   â”‚   â”œâ”€â”€ wsj_archive_crawler.py              # Crawl WSJ archive pages, collect URLs
â”‚   â”‚   â””â”€â”€ wsj_archive_scraper.py              # Download full article contents
â”‚   â”‚
â”‚   â”œâ”€â”€ preprocessing/
â”‚   â”‚   â”œâ”€â”€ clean_database.py                   # Filter articles by section, length, duplicates
â”‚   â”‚   â”œâ”€â”€ corpus_cleaning.py                  # Remove UI/meta elements from text
â”‚   â”‚   â”œâ”€â”€ reduce_db_for_sentiment.py          # Extract subset for sentiment analysis
â”‚   â”‚   â”œâ”€â”€ combine_article_dbs.py              # Merge yearly DBs into one CSV
â”‚   â”‚   â”œâ”€â”€ fix_article_ids.py                  # Ensure uniquenes of article IDs
â”‚   â”‚   â”œâ”€â”€ section_filtering.py                # Remove irrelevant WSJ sections
â”‚   â”‚   â””â”€â”€ simple_ai_filter.py                 # Mark articles with AI keywords
â”‚   â”‚
â”‚   â”œâ”€â”€ annotation/
â”‚   â”‚   â”œâ”€â”€ comparing_annotations.py            # Resolve annotator conflicts
â”‚   â”‚   â””â”€â”€ label_articles.py                   # Interactive annotation tool (AI/Hype)
â”‚   â”‚
â”‚   â”œâ”€â”€ modelling/
â”‚   â”‚   â”œâ”€â”€ ai_windows.py                       # Extract contextual snippets around AI terms
â”‚   â”‚   â”œâ”€â”€ calculate_summary_statistics.py     # Descriptive stats for AINI
â”‚   â”‚   â”œâ”€â”€ compute_extrema.py                  # Extremes (Min/Max) of AINI variants
â”‚   â”‚   â”œâ”€â”€ construct_AINI_variables.py         # Build AINI time series (normalization, EMAs)
â”‚   â”‚   â”œâ”€â”€ CustomFinBERT.py                    # Custom FinBERT with dropout & class weights
â”‚   â”‚   â”œâ”€â”€ stationarity_testing.py             # Stationarity tests (ADF, PP)
â”‚   â”‚   â”œâ”€â”€ estimate_granger_causality.py       # Granger causality with bootstrap
â”‚   â”‚   â”œâ”€â”€ estimate_transfer_entropy.py        # infer KSG-based Entropy (legacy)
â”‚   â”‚   â”œâ”€â”€ format_te_gc_inputs.py              # prepare data of KSG estimator (legacy)
â”‚   â”‚   â”œâ”€â”€ predict_binary_AINI_FinBERT.py      # AI vs. Non-AI classification
â”‚   â”‚   â””â”€â”€ predict_AINI_FinBERT_window.py      # Context-based sentiment inference
â”‚   â”‚
â”‚   â”œâ”€â”€ visualizations/
â”‚   â”‚   â”œâ”€â”€ construct_tables.py                 # create reporting for Granger causality
â”‚   â”‚   â”œâ”€â”€ plot_functions.py                   # plot various AINI series
â”‚   â”‚   â”œâ”€â”€ plot_granger_causality.py           # plot regression results
â”‚   â”‚   â”œâ”€â”€ prepare PPT.py                      # buils PowerPoint regression tables
â”‚   â”‚   â”œâ”€â”€ read_articles.py                    # visualize article content
â”‚   â”‚   â””â”€â”€ stationarity_report.py              # create reporting for KPSS, ADF & PP
â”‚   â”‚   
â”‚   â”‚
â”‚   â”œâ”€â”€ databases/
â”‚   â”‚   â””â”€â”€ create_database.py                  # Create SQL DB structure
â”‚   â”‚
â”‚
â”œâ”€â”€ scripts/                                    # CLI wrappers for reproducibility
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ estimate_collider_granger_causality.py
â”‚   â”œâ”€â”€ init_jvm.py
â”‚   â”œâ”€â”€ run_clean_database.py
â”‚   â”œâ”€â”€ run_combine_article_dbs.py
â”‚   â”œâ”€â”€ run_construct_AINI_variables.py
â”‚   â”œâ”€â”€ run_create_database.py
â”‚   â”œâ”€â”€ run_estimate_granger_causality.py
â”‚   â”œâ”€â”€ run_estimate_ols.py
â”‚   â”œâ”€â”€ run_fix_article_ids.py
â”‚   â”œâ”€â”€ run_load_financial_data.py
â”‚   â”œâ”€â”€ run_naive_labeling.py
â”‚   â”œâ”€â”€ run_predict_AINI_FinBERT_prelabeled_fin.py
â”‚   â”œâ”€â”€ run_predict_AINI_FinBERT_window.py
â”‚   â”œâ”€â”€ run_predict_binary_AINI_FinBERT.py
â”‚   â”œâ”€â”€ run_predict_investor_sentiment.py
â”‚   â”œâ”€â”€ run_reduce_db_for_sentiment.py
â”‚   â”œâ”€â”€ run_stationarity_testing.py
â”‚   â”œâ”€â”€ run_wsj_crawler.py
â”‚   â””â”€â”€ run_wsj_scraper.py
â”‚ 
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ analyse_gc_results.ipynb               # Analyse Granger causality results
â”‚   â”œâ”€â”€ benchmark_windows.ipynb                # Compare flagging models
â”‚   â”œâ”€â”€ calc_CAPM.ipynb                        # Run CAPM regressions
â”‚   â”œâ”€â”€ compare_annotations.ipynb              # Compare annotation windows
â”‚   â”œâ”€â”€ compare_class_variants.ipynb           # Investigate different classification setups
â”‚   â”œâ”€â”€ exploratory_analysis_aini.ipynb        # Analyse AINI time series 
â”‚   â”œâ”€â”€ exploratory_custom_fin.ipynb           # Analyse results of finetuned FinBERT 
â”‚   â”œâ”€â”€ exploratory_analysis_raw_res.ipynb     # Analyse FinBERT annotations
â”‚   â”œâ”€â”€ exploratory_analysis_wsj.ipynb         # Analyse WSJ-data
â”‚   â”œâ”€â”€ label_manually.ipynb                   # Annotate articles
â”‚   â”œâ”€â”€ sample_articles.ipynb                  # Sample articles for annotation
â”‚   â”œâ”€â”€ stationarity_evaluation.ipynb          # Investigate stationarity issues
â”‚   â”œâ”€â”€ subset_for_latex.ipynb                 # Prepare for LaTex reporting (legacy)
â”‚   â”œâ”€â”€ train_FinBERT_annot.ipynb              # Finetune custom FinBERT
â”‚   â””â”€â”€ visualize_aini_variables.ipynb         # Inspect AINI (legacy)
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                                   # Raw data (articles, financials)
â”‚   â”œâ”€â”€ interim/                               # Intermediate data (annotation, subsets)
â”‚   â””â”€â”€ processed/
â”‚       â”œâ”€â”€ variables/                         # Final variables (AINI, GC, TE etc.)
â”‚       â””â”€â”€ articles/                          # Cleaned article texts
â”‚
â””â”€â”€ models/                                    # Fine-tuned FinBERT



# Data Catalog

This catalog documents the datasets used and generated in the **AI Narrative Index (AINI)** project.  
The structure follows **MLOps best practices**:

- **Traceability:** every dataset is linked to its generating script  
- **Reproducibility:** the raw â†’ interim â†’ processed pipeline is fully transparent  
- **Versioning:** placeholders `{year}` / `{vers}` separate time ranges and versions  
- **Auditability:** all transformations are fully documented  

---

## ğŸ“‚ `data/raw/`

Immutable raw data after collection.  
Single source of truth for all downstream steps.  

### ğŸ“‚ `articles/`

| File | Description | Origin |
|------|-------------|--------|
| `articlesWSJ_{year}.db` | WSJ raw databases with `articles` and `articles_index` | Created via `create_database.py`, filled by `wsj_archive_scraper.py` & `wsj_archive_crawler.py` |

### ğŸ“‚ `financial/`

All files contain OHLCV data: `Date`, `Ticker`, `Open`, `High`, `Low`, `Close`, `Adj Close`, `Volume`.  
Generated with `load_financial_data.py`.  

| File | Description |
|------|-------------|
| `{TICKER}_full_2023_2025.csv` | Daily OHLCV for individual tickers (e.g., `AAPL`, `NVDA`, `MSFT`) |
| `full_daily_2023_2025.csv` | Aggregated OHLCV data for all tickers |

---

## ğŸ“‚ `data/interim/`

Storage for experiments, human-in-the-loop tasks, and partially processed data.  
Used for **annotation, sampling, and benchmarks**.  

### Sampling & Annotation

| File | Description | Origin |
|------|-------------|--------|
| `articles_WSJ_batch_{1â€“4}.csv` | Random samples for annotation | `sample_articles.ipynb` |
| `articles_WSJ_sub500.csv` | Initial 500-article subset (basis for batches) | `sample_articles.ipynb` |
| `articles_WSJ_batch_{n}_annotator.csv` | Labels from professional annotator | External â†’ Import |
| `articles_WSJ_batch_{n}_author.csv` | Authorâ€™s labels | `label_manually.ipynb` |
| `*_subsample_author.csv` | 25% author subsample | Manual selection |

---

## ğŸ“‚ `data/processed/`

Canonical datasets for **training, evaluation, and analysis**.  
Noise and disagreements are resolved.  

### ğŸ“‚ `articles/`

| File | Description | Origin |
|------|-------------|--------|
| `articlesWSJ_clean_{year}.db` | Cleaned WSJ articles (noise removed) | `clean_database.py` (patterns from `corpus_cleaning.py`) |
| `annotated_subsample_WSJ_final.csv` | Consensus labels after conflict resolution | `compare_annotations.ipynb` |
| `articles_WSJ_batch_{n}_final.csv` | Final agreed batch labels | `compare_annotations.ipynb` |

---

## ğŸ“‚ `variables/`

Model outputs, diagnostics, and statistical results.  
All **results are reproducible from code**.  

| File | Description | Origin |
|------|-------------|--------|
| `w0_AINI_variables.csv`, `w1_AINI_variables.csv`, `w2_AINI_variables.csv`, `binary_AINI_variables.csv` | AINI variables (normalized + EMA Î±=0.2/0.8) | `construct_AINI_variables.py` |
| `FinBERT_AINI_prediction_{year}_windowsize_{n}.csv` | Context window predictions (âˆ’1, 0, 1) | `predict_AINI_FinBERT_window.py` |
| `FinBERT_binary_prediction_{year}.csv` | Binary FinBERT predictions on pre-labeled data | `predict_AINI_FinBERT_prelabeled_fin.py` |
| `granger_causality_{spec}.csv` | GC results (AINI â†” returns) with 10k bootstrap + FDR | `estimate_granger_causality.py` |
| `ols_sameday_mbboot_fdr_{spec}.csv` | Contemporaneous OLS effects | `estimate_OLS.py` |
| `diagnostics_{spec}.csv` | OLS residual diagnostics (Ljung-Box, BG, ARCH-LM, â€¦) | `ols_residual_diagnostics.py` |
| `combined_te_results_window_1.csv` | Transfer Entropy results | `calc_entropy.py` |
| `extrema.csv` | Min/Max of AINI variables | `exploratory_analysis_aini.ipynb` |
| `{vers}_AINI_variables.csv` | AINI measures (normalized + EMA, relative) | `run_construct_AINI_variables.py` |
| `naive_AI_labels_{year}.csv` | Dictionary-based AI relevance labels | `label_articles.py` (`naive_labeling`) |
| `n_articles.csv` | Number of articles per day | `exploratory_analysis_aini.ipynb` |

---

## Note

The scraped contents are used exclusively for academic research and are **not** shared publicly for copyright reasons.  
The trained models can be shared upon request (depending on size and usage context).  
